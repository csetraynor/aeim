/*
    aeim is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    aeim is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with aeim.  If not, see <http://www.gnu.org/licenses/>.
*/
#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
#include <rstan/rstaninc.hpp>
// Code generated by Stan version 2.18.0

#include <stan/model/model_header.hpp>

namespace model_MS_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_MS");
    reader.add_event(756, 754, "end", "model_MS");
    return reader;
}

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
exponential_log_haz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 10;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct exponential_log_haz_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta, std::ostream* pstream__) const {
        return exponential_log_haz(eta, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
weibull_log_haz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                    const T2__& shape, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 22;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 23;
        stan::math::assign(res, add(add(stan::math::log(shape),multiply((shape - 1),stan::math::log(t))),eta));
        current_statement_begin__ = 24;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct weibull_log_haz_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                    const T2__& shape, std::ostream* pstream__) const {
        return weibull_log_haz(eta, t, shape, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
gompertz_log_haz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                     const T2__& scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 36;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 37;
        stan::math::assign(res, add(multiply(scale,t),eta));
        current_statement_begin__ = 38;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct gompertz_log_haz_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                     const T2__& scale, std::ostream* pstream__) const {
        return gompertz_log_haz(eta, t, scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
bspline_log_haz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& basis,
                    const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 50;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 51;
        stan::math::assign(res, add(multiply(basis,coefs),eta));
        current_statement_begin__ = 52;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct bspline_log_haz_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& basis,
                    const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) const {
        return bspline_log_haz(eta, basis, coefs, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
quadrature_log_surv(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& qwts,
                        const Eigen::Matrix<T1__, Eigen::Dynamic,1>& log_hazard, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 66;
        local_scalar_t__ res;
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 67;
        stan::math::assign(res, -(dot_product(qwts,stan::math::exp(log_hazard))));
        current_statement_begin__ = 68;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct quadrature_log_surv_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& qwts,
                        const Eigen::Matrix<T1__, Eigen::Dynamic,1>& log_hazard, std::ostream* pstream__) const {
        return quadrature_log_surv(qwts, log_hazard, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
quadrature_log_cdf(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& qwts,
                       const Eigen::Matrix<T1__, Eigen::Dynamic,1>& log_hazard,
                       const int& qnodes,
                       const int& N, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 72;
        int M(0);
        (void) M;  // dummy to suppress unused var warning

        stan::math::fill(M, std::numeric_limits<int>::min());
        stan::math::assign(M,rows(log_hazard));
        current_statement_begin__ = 73;
        validate_non_negative_index("hazard", "M", M);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  hazard(static_cast<Eigen::VectorXd::Index>(M));
        (void) hazard;  // dummy to suppress unused var warning

        stan::math::initialize(hazard, DUMMY_VAR__);
        stan::math::fill(hazard,DUMMY_VAR__);
        stan::math::assign(hazard,stan::math::exp(log_hazard));
        current_statement_begin__ = 74;
        validate_non_negative_index("qwts_mat", "N", N);
        validate_non_negative_index("qwts_mat", "qnodes", qnodes);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  qwts_mat(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(qnodes));
        (void) qwts_mat;  // dummy to suppress unused var warning

        stan::math::initialize(qwts_mat, DUMMY_VAR__);
        stan::math::fill(qwts_mat,DUMMY_VAR__);
        stan::math::assign(qwts_mat,to_matrix(qwts,N,qnodes));
        current_statement_begin__ = 75;
        validate_non_negative_index("haz_mat", "N", N);
        validate_non_negative_index("haz_mat", "qnodes", qnodes);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  haz_mat(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(qnodes));
        (void) haz_mat;  // dummy to suppress unused var warning

        stan::math::initialize(haz_mat, DUMMY_VAR__);
        stan::math::fill(haz_mat,DUMMY_VAR__);
        stan::math::assign(haz_mat,to_matrix(hazard,N,qnodes));
        current_statement_begin__ = 76;
        validate_non_negative_index("chaz", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  chaz(static_cast<Eigen::VectorXd::Index>(N));
        (void) chaz;  // dummy to suppress unused var warning

        stan::math::initialize(chaz, DUMMY_VAR__);
        stan::math::fill(chaz,DUMMY_VAR__);
        stan::math::assign(chaz,rows_dot_product(qwts_mat,haz_mat));
        current_statement_begin__ = 77;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 78;
        stan::math::assign(res, stan::math::log(subtract(1,stan::math::exp(minus(chaz)))));
        current_statement_begin__ = 79;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct quadrature_log_cdf_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& qwts,
                       const Eigen::Matrix<T1__, Eigen::Dynamic,1>& log_hazard,
                       const int& qnodes,
                       const int& N, std::ostream* pstream__) const {
        return quadrature_log_cdf(qwts, log_hazard, qnodes, N, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
quadrature_log_cdf2(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& qwts_lower,
                        const Eigen::Matrix<T1__, Eigen::Dynamic,1>& log_hazard_lower,
                        const Eigen::Matrix<T2__, Eigen::Dynamic,1>& qwts_upper,
                        const Eigen::Matrix<T3__, Eigen::Dynamic,1>& log_hazard_upper,
                        const int& qnodes,
                        const int& N, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 85;
        int M(0);
        (void) M;  // dummy to suppress unused var warning

        stan::math::fill(M, std::numeric_limits<int>::min());
        stan::math::assign(M,rows(log_hazard_lower));
        current_statement_begin__ = 86;
        validate_non_negative_index("hazard_lower", "M", M);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  hazard_lower(static_cast<Eigen::VectorXd::Index>(M));
        (void) hazard_lower;  // dummy to suppress unused var warning

        stan::math::initialize(hazard_lower, DUMMY_VAR__);
        stan::math::fill(hazard_lower,DUMMY_VAR__);
        stan::math::assign(hazard_lower,stan::math::exp(log_hazard_lower));
        current_statement_begin__ = 87;
        validate_non_negative_index("hazard_upper", "M", M);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  hazard_upper(static_cast<Eigen::VectorXd::Index>(M));
        (void) hazard_upper;  // dummy to suppress unused var warning

        stan::math::initialize(hazard_upper, DUMMY_VAR__);
        stan::math::fill(hazard_upper,DUMMY_VAR__);
        stan::math::assign(hazard_upper,stan::math::exp(log_hazard_upper));
        current_statement_begin__ = 88;
        validate_non_negative_index("qwts_lower_mat", "N", N);
        validate_non_negative_index("qwts_lower_mat", "qnodes", qnodes);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  qwts_lower_mat(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(qnodes));
        (void) qwts_lower_mat;  // dummy to suppress unused var warning

        stan::math::initialize(qwts_lower_mat, DUMMY_VAR__);
        stan::math::fill(qwts_lower_mat,DUMMY_VAR__);
        stan::math::assign(qwts_lower_mat,to_matrix(qwts_lower,N,qnodes));
        current_statement_begin__ = 89;
        validate_non_negative_index("qwts_upper_mat", "N", N);
        validate_non_negative_index("qwts_upper_mat", "qnodes", qnodes);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  qwts_upper_mat(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(qnodes));
        (void) qwts_upper_mat;  // dummy to suppress unused var warning

        stan::math::initialize(qwts_upper_mat, DUMMY_VAR__);
        stan::math::fill(qwts_upper_mat,DUMMY_VAR__);
        stan::math::assign(qwts_upper_mat,to_matrix(qwts_upper,N,qnodes));
        current_statement_begin__ = 90;
        validate_non_negative_index("haz_lower_mat", "N", N);
        validate_non_negative_index("haz_lower_mat", "qnodes", qnodes);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  haz_lower_mat(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(qnodes));
        (void) haz_lower_mat;  // dummy to suppress unused var warning

        stan::math::initialize(haz_lower_mat, DUMMY_VAR__);
        stan::math::fill(haz_lower_mat,DUMMY_VAR__);
        stan::math::assign(haz_lower_mat,to_matrix(hazard_lower,N,qnodes));
        current_statement_begin__ = 91;
        validate_non_negative_index("haz_upper_mat", "N", N);
        validate_non_negative_index("haz_upper_mat", "qnodes", qnodes);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,Eigen::Dynamic>  haz_upper_mat(static_cast<Eigen::VectorXd::Index>(N),static_cast<Eigen::VectorXd::Index>(qnodes));
        (void) haz_upper_mat;  // dummy to suppress unused var warning

        stan::math::initialize(haz_upper_mat, DUMMY_VAR__);
        stan::math::fill(haz_upper_mat,DUMMY_VAR__);
        stan::math::assign(haz_upper_mat,to_matrix(hazard_upper,N,qnodes));
        current_statement_begin__ = 92;
        validate_non_negative_index("chaz_lower", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  chaz_lower(static_cast<Eigen::VectorXd::Index>(N));
        (void) chaz_lower;  // dummy to suppress unused var warning

        stan::math::initialize(chaz_lower, DUMMY_VAR__);
        stan::math::fill(chaz_lower,DUMMY_VAR__);
        stan::math::assign(chaz_lower,rows_dot_product(qwts_lower_mat,haz_lower_mat));
        current_statement_begin__ = 93;
        validate_non_negative_index("chaz_upper", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  chaz_upper(static_cast<Eigen::VectorXd::Index>(N));
        (void) chaz_upper;  // dummy to suppress unused var warning

        stan::math::initialize(chaz_upper, DUMMY_VAR__);
        stan::math::fill(chaz_upper,DUMMY_VAR__);
        stan::math::assign(chaz_upper,rows_dot_product(qwts_upper_mat,haz_upper_mat));
        current_statement_begin__ = 94;
        validate_non_negative_index("surv_lower", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_lower(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_lower;  // dummy to suppress unused var warning

        stan::math::initialize(surv_lower, DUMMY_VAR__);
        stan::math::fill(surv_lower,DUMMY_VAR__);
        stan::math::assign(surv_lower,stan::math::exp(minus(chaz_lower)));
        current_statement_begin__ = 95;
        validate_non_negative_index("surv_upper", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_upper(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_upper;  // dummy to suppress unused var warning

        stan::math::initialize(surv_upper, DUMMY_VAR__);
        stan::math::fill(surv_upper,DUMMY_VAR__);
        stan::math::assign(surv_upper,stan::math::exp(minus(chaz_upper)));
        current_statement_begin__ = 96;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 97;
        stan::math::assign(res, stan::math::log(subtract(surv_lower,surv_upper)));
        current_statement_begin__ = 98;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct quadrature_log_cdf2_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& qwts_lower,
                        const Eigen::Matrix<T1__, Eigen::Dynamic,1>& log_hazard_lower,
                        const Eigen::Matrix<T2__, Eigen::Dynamic,1>& qwts_upper,
                        const Eigen::Matrix<T3__, Eigen::Dynamic,1>& log_hazard_upper,
                        const int& qnodes,
                        const int& N, std::ostream* pstream__) const {
        return quadrature_log_cdf2(qwts_lower, log_hazard_lower, qwts_upper, log_hazard_upper, qnodes, N, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
mspline_log_haz(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& basis,
                    const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 111;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 112;
        stan::math::assign(res, add(stan::math::log(multiply(basis,coefs)),eta));
        current_statement_begin__ = 113;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct mspline_log_haz_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& basis,
                    const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) const {
        return mspline_log_haz(eta, basis, coefs, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 127;
        local_scalar_t__ z2;
        (void) z2;  // dummy to suppress unused var warning

        stan::math::initialize(z2, DUMMY_VAR__);
        stan::math::fill(z2,DUMMY_VAR__);
        stan::math::assign(z2,square(z));
        current_statement_begin__ = 128;
        local_scalar_t__ z3;
        (void) z3;  // dummy to suppress unused var warning

        stan::math::initialize(z3, DUMMY_VAR__);
        stan::math::fill(z3,DUMMY_VAR__);
        stan::math::assign(z3,(z2 * z));
        current_statement_begin__ = 129;
        local_scalar_t__ z5;
        (void) z5;  // dummy to suppress unused var warning

        stan::math::initialize(z5, DUMMY_VAR__);
        stan::math::fill(z5,DUMMY_VAR__);
        stan::math::assign(z5,(z2 * z3));
        current_statement_begin__ = 130;
        local_scalar_t__ z7;
        (void) z7;  // dummy to suppress unused var warning

        stan::math::initialize(z7, DUMMY_VAR__);
        stan::math::fill(z7,DUMMY_VAR__);
        stan::math::assign(z7,(z2 * z5));
        current_statement_begin__ = 131;
        local_scalar_t__ z9;
        (void) z9;  // dummy to suppress unused var warning

        stan::math::initialize(z9, DUMMY_VAR__);
        stan::math::fill(z9,DUMMY_VAR__);
        stan::math::assign(z9,(z2 * z7));
        current_statement_begin__ = 132;
        local_scalar_t__ df2;
        (void) df2;  // dummy to suppress unused var warning

        stan::math::initialize(df2, DUMMY_VAR__);
        stan::math::fill(df2,DUMMY_VAR__);
        stan::math::assign(df2,square(df));
        current_statement_begin__ = 133;
        local_scalar_t__ df3;
        (void) df3;  // dummy to suppress unused var warning

        stan::math::initialize(df3, DUMMY_VAR__);
        stan::math::fill(df3,DUMMY_VAR__);
        stan::math::assign(df3,(df2 * df));
        current_statement_begin__ = 134;
        local_scalar_t__ df4;
        (void) df4;  // dummy to suppress unused var warning

        stan::math::initialize(df4, DUMMY_VAR__);
        stan::math::fill(df4,DUMMY_VAR__);
        stan::math::assign(df4,(df2 * df2));


        current_statement_begin__ = 135;
        return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

double
coefs_lb(const int& type, std::ostream* pstream__) {
    typedef double local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 147;
        local_scalar_t__ lb;
        (void) lb;  // dummy to suppress unused var warning

        stan::math::initialize(lb, DUMMY_VAR__);
        stan::math::fill(lb,DUMMY_VAR__);


        current_statement_begin__ = 148;
        if (as_bool(logical_eq(type,2))) {
            current_statement_begin__ = 149;
            stan::math::assign(lb, stan::math::negative_infinity());
        } else if (as_bool(logical_eq(type,3))) {
            current_statement_begin__ = 151;
            stan::math::assign(lb, stan::math::negative_infinity());
        } else {
            current_statement_begin__ = 153;
            stan::math::assign(lb, 0);
        }
        current_statement_begin__ = 154;
        return stan::math::promote_scalar<fun_return_scalar_t__>(lb);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct coefs_lb_functor__ {
            double
    operator()(const int& type, std::ostream* pstream__) const {
        return coefs_lb(type, pstream__);
    }
};

template <typename T0__, typename T2__, typename T3__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T2__, T3__>::type, Eigen::Dynamic,1>
make_beta(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
              const int& prior_dist,
              const Eigen::Matrix<T2__, Eigen::Dynamic,1>& prior_mean,
              const Eigen::Matrix<T3__, Eigen::Dynamic,1>& prior_scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 167;
        validate_non_negative_index("beta", "rows(z_beta)", rows(z_beta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta(static_cast<Eigen::VectorXd::Index>(rows(z_beta)));
        (void) beta;  // dummy to suppress unused var warning

        stan::math::initialize(beta, DUMMY_VAR__);
        stan::math::fill(beta,DUMMY_VAR__);


        current_statement_begin__ = 170;
        stan::math::assign(beta, add(elt_multiply(z_beta,prior_scale),prior_mean));
        current_statement_begin__ = 171;
        return stan::math::promote_scalar<fun_return_scalar_t__>(beta);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_beta_functor__ {
    template <typename T0__, typename T2__, typename T3__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T2__, T3__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
              const int& prior_dist,
              const Eigen::Matrix<T2__, Eigen::Dynamic,1>& prior_mean,
              const Eigen::Matrix<T3__, Eigen::Dynamic,1>& prior_scale, std::ostream* pstream__) const {
        return make_beta(z_beta, prior_dist, prior_mean, prior_scale, pstream__);
    }
};

template <typename T0__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T_lp__>::type
beta_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
            const int& prior_dist, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T_lp__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 190;
        lp_accum__.add(normal_log(z_beta,0,1));
        current_statement_begin__ = 192;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct beta_lp_functor__ {
    template <typename T0__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T_lp__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& z_beta,
            const int& prior_dist, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return beta_lp(z_beta, prior_dist, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T_lp__>::type
basehaz_lp(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& aux_unscaled,
               const int& dist, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T_lp__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 205;
        if (as_bool(logical_gt(dist,0))) {

            current_statement_begin__ = 206;
            if (as_bool(logical_eq(dist,1))) {
                current_statement_begin__ = 207;
                lp_accum__.add(normal_log(aux_unscaled,0,1));
            } else {
                current_statement_begin__ = 209;
                lp_accum__.add(exponential_log(aux_unscaled,1));
            }
        }
        current_statement_begin__ = 211;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct basehaz_lp_functor__ {
    template <typename T0__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T_lp__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& aux_unscaled,
               const int& dist, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return basehaz_lp(aux_unscaled, dist, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T2__, typename T3__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T2__, T3__, T_lp__>::type
gamma_lp(const T0__& gamma,
             const int& dist,
             const T2__& mean,
             const T3__& scale, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T2__, T3__, T_lp__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 225;
        if (as_bool(logical_eq(dist,1))) {
            current_statement_begin__ = 226;
            lp_accum__.add(normal_log(gamma,mean,scale));
        }
        current_statement_begin__ = 230;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct gamma_lp_functor__ {
    template <typename T0__, typename T2__, typename T3__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T2__, T3__, T_lp__>::type
    operator()(const T0__& gamma,
             const int& dist,
             const T2__& mean,
             const T3__& scale, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return gamma_lp(gamma, dist, mean, scale, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
pow_vec(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
            const T1__& y, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 241;
        int N(0);
        (void) N;  // dummy to suppress unused var warning

        stan::math::fill(N, std::numeric_limits<int>::min());
        stan::math::assign(N,rows(x));
        current_statement_begin__ = 242;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 243;
        for (int n = 1; n <= N; ++n) {
            current_statement_begin__ = 244;
            stan::model::assign(res, 
                        stan::model::cons_list(stan::model::index_uni(n), stan::model::nil_index_list()), 
                        pow(get_base1(x,n,"x",1),y), 
                        "assigning variable res");
        }
        current_statement_begin__ = 245;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pow_vec_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& x,
            const T1__& y, std::ostream* pstream__) const {
        return pow_vec(x, y, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
exponential_log_surv(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 256;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 257;
        stan::math::assign(res, elt_multiply(minus(t),stan::math::exp(eta)));
        current_statement_begin__ = 258;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct exponential_log_surv_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t, std::ostream* pstream__) const {
        return exponential_log_surv(eta, t, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
exponential_log_cdf(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                        const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 262;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 263;
        stan::math::assign(res, stan::math::log(subtract(1,stan::math::exp(elt_multiply(minus(t),stan::math::exp(eta))))));
        current_statement_begin__ = 264;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct exponential_log_cdf_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                        const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t, std::ostream* pstream__) const {
        return exponential_log_cdf(eta, t, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
exponential_log_cdf2(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t_lower,
                         const Eigen::Matrix<T2__, Eigen::Dynamic,1>& t_upper, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 268;
        int N(0);
        (void) N;  // dummy to suppress unused var warning

        stan::math::fill(N, std::numeric_limits<int>::min());
        stan::math::assign(N,rows(eta));
        current_statement_begin__ = 269;
        validate_non_negative_index("exp_eta", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  exp_eta(static_cast<Eigen::VectorXd::Index>(N));
        (void) exp_eta;  // dummy to suppress unused var warning

        stan::math::initialize(exp_eta, DUMMY_VAR__);
        stan::math::fill(exp_eta,DUMMY_VAR__);
        stan::math::assign(exp_eta,stan::math::exp(eta));
        current_statement_begin__ = 270;
        validate_non_negative_index("surv_lower", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_lower(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_lower;  // dummy to suppress unused var warning

        stan::math::initialize(surv_lower, DUMMY_VAR__);
        stan::math::fill(surv_lower,DUMMY_VAR__);
        stan::math::assign(surv_lower,stan::math::exp(elt_multiply(minus(t_lower),exp_eta)));
        current_statement_begin__ = 271;
        validate_non_negative_index("surv_upper", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_upper(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_upper;  // dummy to suppress unused var warning

        stan::math::initialize(surv_upper, DUMMY_VAR__);
        stan::math::fill(surv_upper,DUMMY_VAR__);
        stan::math::assign(surv_upper,stan::math::exp(elt_multiply(minus(t_upper),exp_eta)));
        current_statement_begin__ = 272;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 273;
        stan::math::assign(res, stan::math::log(subtract(surv_lower,surv_upper)));
        current_statement_begin__ = 274;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct exponential_log_cdf2_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                         const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t_lower,
                         const Eigen::Matrix<T2__, Eigen::Dynamic,1>& t_upper, std::ostream* pstream__) const {
        return exponential_log_cdf2(eta, t_lower, t_upper, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
weibull_log_surv(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                     const T2__& shape, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 286;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 287;
        stan::math::assign(res, elt_multiply(minus(pow_vec(t,shape, pstream__)),stan::math::exp(eta)));
        current_statement_begin__ = 288;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct weibull_log_surv_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                     const T2__& shape, std::ostream* pstream__) const {
        return weibull_log_surv(eta, t, shape, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
weibull_log_cdf(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                    const T2__& shape, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 292;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 293;
        stan::math::assign(res, stan::math::log(subtract(1,stan::math::exp(elt_multiply(minus(pow_vec(t,shape, pstream__)),stan::math::exp(eta))))));
        current_statement_begin__ = 294;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct weibull_log_cdf_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                    const T2__& shape, std::ostream* pstream__) const {
        return weibull_log_cdf(eta, t, shape, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
weibull_log_cdf2(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t_lower,
                     const Eigen::Matrix<T2__, Eigen::Dynamic,1>& t_upper,
                     const T3__& shape, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 298;
        int N(0);
        (void) N;  // dummy to suppress unused var warning

        stan::math::fill(N, std::numeric_limits<int>::min());
        stan::math::assign(N,rows(eta));
        current_statement_begin__ = 299;
        validate_non_negative_index("exp_eta", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  exp_eta(static_cast<Eigen::VectorXd::Index>(N));
        (void) exp_eta;  // dummy to suppress unused var warning

        stan::math::initialize(exp_eta, DUMMY_VAR__);
        stan::math::fill(exp_eta,DUMMY_VAR__);
        stan::math::assign(exp_eta,stan::math::exp(eta));
        current_statement_begin__ = 300;
        validate_non_negative_index("surv_lower", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_lower(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_lower;  // dummy to suppress unused var warning

        stan::math::initialize(surv_lower, DUMMY_VAR__);
        stan::math::fill(surv_lower,DUMMY_VAR__);
        stan::math::assign(surv_lower,stan::math::exp(elt_multiply(minus(pow_vec(t_lower,shape, pstream__)),exp_eta)));
        current_statement_begin__ = 301;
        validate_non_negative_index("surv_upper", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_upper(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_upper;  // dummy to suppress unused var warning

        stan::math::initialize(surv_upper, DUMMY_VAR__);
        stan::math::fill(surv_upper,DUMMY_VAR__);
        stan::math::assign(surv_upper,stan::math::exp(elt_multiply(minus(pow_vec(t_upper,shape, pstream__)),exp_eta)));
        current_statement_begin__ = 302;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 303;
        stan::math::assign(res, stan::math::log(subtract(surv_lower,surv_upper)));
        current_statement_begin__ = 304;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct weibull_log_cdf2_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t_lower,
                     const Eigen::Matrix<T2__, Eigen::Dynamic,1>& t_upper,
                     const T3__& shape, std::ostream* pstream__) const {
        return weibull_log_cdf2(eta, t_lower, t_upper, shape, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
gompertz_log_surv(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                      const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                      const T2__& scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 316;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 317;
        stan::math::assign(res, elt_multiply(multiply(inv(scale),minus(subtract(stan::math::exp(multiply(scale,t)),1))),stan::math::exp(eta)));
        current_statement_begin__ = 318;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct gompertz_log_surv_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                      const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                      const T2__& scale, std::ostream* pstream__) const {
        return gompertz_log_surv(eta, t, scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
gompertz_log_cdf(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                     const T2__& scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 322;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 323;
        stan::math::assign(res, stan::math::log(subtract(1,stan::math::exp(elt_multiply(multiply(inv(scale),minus(subtract(stan::math::exp(multiply(scale,t)),1))),stan::math::exp(eta))))));
        current_statement_begin__ = 324;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct gompertz_log_cdf_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t,
                     const T2__& scale, std::ostream* pstream__) const {
        return gompertz_log_cdf(eta, t, scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
gompertz_log_cdf2(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                      const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t_lower,
                      const Eigen::Matrix<T2__, Eigen::Dynamic,1>& t_upper,
                      const T3__& scale, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 328;
        int N(0);
        (void) N;  // dummy to suppress unused var warning

        stan::math::fill(N, std::numeric_limits<int>::min());
        stan::math::assign(N,rows(eta));
        current_statement_begin__ = 329;
        local_scalar_t__ inv_scale;
        (void) inv_scale;  // dummy to suppress unused var warning

        stan::math::initialize(inv_scale, DUMMY_VAR__);
        stan::math::fill(inv_scale,DUMMY_VAR__);
        stan::math::assign(inv_scale,inv(scale));
        current_statement_begin__ = 330;
        validate_non_negative_index("exp_eta", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  exp_eta(static_cast<Eigen::VectorXd::Index>(N));
        (void) exp_eta;  // dummy to suppress unused var warning

        stan::math::initialize(exp_eta, DUMMY_VAR__);
        stan::math::fill(exp_eta,DUMMY_VAR__);
        stan::math::assign(exp_eta,stan::math::exp(eta));
        current_statement_begin__ = 331;
        validate_non_negative_index("surv_lower", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_lower(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_lower;  // dummy to suppress unused var warning

        stan::math::initialize(surv_lower, DUMMY_VAR__);
        stan::math::fill(surv_lower,DUMMY_VAR__);
        stan::math::assign(surv_lower,stan::math::exp(elt_multiply(multiply(inv_scale,minus(subtract(stan::math::exp(multiply(scale,t_lower)),1))),exp_eta)));
        current_statement_begin__ = 332;
        validate_non_negative_index("surv_upper", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_upper(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_upper;  // dummy to suppress unused var warning

        stan::math::initialize(surv_upper, DUMMY_VAR__);
        stan::math::fill(surv_upper,DUMMY_VAR__);
        stan::math::assign(surv_upper,stan::math::exp(elt_multiply(multiply(inv_scale,minus(subtract(stan::math::exp(multiply(scale,t_upper)),1))),exp_eta)));
        current_statement_begin__ = 333;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 334;
        stan::math::assign(res, stan::math::log(subtract(surv_lower,surv_upper)));
        current_statement_begin__ = 335;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct gompertz_log_cdf2_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                      const Eigen::Matrix<T1__, Eigen::Dynamic,1>& t_lower,
                      const Eigen::Matrix<T2__, Eigen::Dynamic,1>& t_upper,
                      const T3__& scale, std::ostream* pstream__) const {
        return gompertz_log_cdf2(eta, t_lower, t_upper, scale, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
mspline_log_surv(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& ibasis,
                     const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 347;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 348;
        stan::math::assign(res, elt_multiply(minus(multiply(ibasis,coefs)),stan::math::exp(eta)));
        current_statement_begin__ = 349;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct mspline_log_surv_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& ibasis,
                     const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) const {
        return mspline_log_surv(eta, ibasis, coefs, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
mspline_log_cdf(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& ibasis,
                    const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 353;
        validate_non_negative_index("res", "rows(eta)", rows(eta));
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(rows(eta)));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 354;
        stan::math::assign(res, stan::math::log(subtract(1,stan::math::exp(elt_multiply(minus(multiply(ibasis,coefs)),stan::math::exp(eta))))));
        current_statement_begin__ = 355;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct mspline_log_cdf_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                    const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& ibasis,
                    const Eigen::Matrix<T2__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) const {
        return mspline_log_cdf(eta, ibasis, coefs, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
mspline_log_cdf2(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& ibasis_lower,
                     const Eigen::Matrix<T2__, Eigen::Dynamic,Eigen::Dynamic>& ibasis_upper,
                     const Eigen::Matrix<T3__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 359;
        int N(0);
        (void) N;  // dummy to suppress unused var warning

        stan::math::fill(N, std::numeric_limits<int>::min());
        stan::math::assign(N,rows(eta));
        current_statement_begin__ = 360;
        validate_non_negative_index("exp_eta", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  exp_eta(static_cast<Eigen::VectorXd::Index>(N));
        (void) exp_eta;  // dummy to suppress unused var warning

        stan::math::initialize(exp_eta, DUMMY_VAR__);
        stan::math::fill(exp_eta,DUMMY_VAR__);
        stan::math::assign(exp_eta,stan::math::exp(eta));
        current_statement_begin__ = 361;
        validate_non_negative_index("surv_lower", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_lower(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_lower;  // dummy to suppress unused var warning

        stan::math::initialize(surv_lower, DUMMY_VAR__);
        stan::math::fill(surv_lower,DUMMY_VAR__);
        stan::math::assign(surv_lower,stan::math::exp(elt_multiply(minus(multiply(ibasis_lower,coefs)),exp_eta)));
        current_statement_begin__ = 362;
        validate_non_negative_index("surv_upper", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  surv_upper(static_cast<Eigen::VectorXd::Index>(N));
        (void) surv_upper;  // dummy to suppress unused var warning

        stan::math::initialize(surv_upper, DUMMY_VAR__);
        stan::math::fill(surv_upper,DUMMY_VAR__);
        stan::math::assign(surv_upper,stan::math::exp(elt_multiply(minus(multiply(ibasis_upper,coefs)),exp_eta)));
        current_statement_begin__ = 363;
        validate_non_negative_index("res", "N", N);
        Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  res(static_cast<Eigen::VectorXd::Index>(N));
        (void) res;  // dummy to suppress unused var warning

        stan::math::initialize(res, DUMMY_VAR__);
        stan::math::fill(res,DUMMY_VAR__);


        current_statement_begin__ = 364;
        stan::math::assign(res, stan::math::log(subtract(surv_lower,surv_upper)));
        current_statement_begin__ = 365;
        return stan::math::promote_scalar<fun_return_scalar_t__>(res);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct mspline_log_cdf2_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__>::type, Eigen::Dynamic,1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic,1>& eta,
                     const Eigen::Matrix<T1__, Eigen::Dynamic,Eigen::Dynamic>& ibasis_lower,
                     const Eigen::Matrix<T2__, Eigen::Dynamic,Eigen::Dynamic>& ibasis_upper,
                     const Eigen::Matrix<T3__, Eigen::Dynamic,1>& coefs, std::ostream* pstream__) const {
        return mspline_log_cdf2(eta, ibasis_lower, ibasis_upper, coefs, pstream__);
    }
};

#include <meta_header.hpp>
 class model_MS : public prob_grad {
private:
    int nevent01;
    int nevent02;
    int nevent12;
    int nrcens01;
    int nrcens02;
    int nrcens12;
    int K01;
    int K02;
    int K12;
    double log_crude_event_rate01;
    double log_crude_event_rate02;
    double log_crude_event_rate12;
    vector_d t_event01;
    vector_d t_event02;
    vector_d t_event12;
    vector_d t_rcens01;
    vector_d t_rcens02;
    vector_d t_rcens12;
    vector_d x_bar01;
    vector_d x_bar02;
    vector_d x_bar12;
    matrix_d x_event01;
    matrix_d x_event02;
    matrix_d x_event12;
    matrix_d x_rcens01;
    matrix_d x_rcens02;
    matrix_d x_rcens12;
    int nvars01;
    int nvars02;
    int nvars12;
    matrix_d basis_event01;
    matrix_d basis_event02;
    matrix_d basis_event12;
    matrix_d ibasis_event01;
    matrix_d ibasis_event02;
    matrix_d ibasis_event12;
    matrix_d ibasis_rcens01;
    matrix_d ibasis_rcens02;
    matrix_d ibasis_rcens12;
    int type01;
    int type02;
    int type12;
    int has_intercept01;
    int has_intercept02;
    int has_intercept12;
    int prior_PD;
    int prior_dist01;
    int prior_dist02;
    int prior_dist12;
    vector_d prior_mean01;
    vector_d prior_mean02;
    vector_d prior_mean12;
    vector_d prior_scale01;
    vector_d prior_scale02;
    vector_d prior_scale12;
    int prior_dist_for_intercept01;
    int prior_dist_for_intercept02;
    int prior_dist_for_intercept12;
    double prior_mean_for_intercept01;
    double prior_scale_for_intercept01;
    double prior_mean_for_intercept02;
    double prior_scale_for_intercept02;
    double prior_mean_for_intercept12;
    double prior_scale_for_intercept12;
    int prior_dist_for_aux01;
    int prior_dist_for_aux02;
    int prior_dist_for_aux12;
    vector_d prior_scale_for_aux01;
    vector_d prior_scale_for_aux02;
    vector_d prior_scale_for_aux12;
public:
    model_MS(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_MS(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        typedef double local_scalar_t__;

        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_MS_namespace::model_MS";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        // initialize member variables
        try {
            current_statement_begin__ = 374;
            context__.validate_dims("data initialization", "nevent01", "int", context__.to_vec());
            nevent01 = int(0);
            vals_i__ = context__.vals_i("nevent01");
            pos__ = 0;
            nevent01 = vals_i__[pos__++];
            current_statement_begin__ = 375;
            context__.validate_dims("data initialization", "nevent02", "int", context__.to_vec());
            nevent02 = int(0);
            vals_i__ = context__.vals_i("nevent02");
            pos__ = 0;
            nevent02 = vals_i__[pos__++];
            current_statement_begin__ = 376;
            context__.validate_dims("data initialization", "nevent12", "int", context__.to_vec());
            nevent12 = int(0);
            vals_i__ = context__.vals_i("nevent12");
            pos__ = 0;
            nevent12 = vals_i__[pos__++];
            current_statement_begin__ = 378;
            context__.validate_dims("data initialization", "nrcens01", "int", context__.to_vec());
            nrcens01 = int(0);
            vals_i__ = context__.vals_i("nrcens01");
            pos__ = 0;
            nrcens01 = vals_i__[pos__++];
            current_statement_begin__ = 379;
            context__.validate_dims("data initialization", "nrcens02", "int", context__.to_vec());
            nrcens02 = int(0);
            vals_i__ = context__.vals_i("nrcens02");
            pos__ = 0;
            nrcens02 = vals_i__[pos__++];
            current_statement_begin__ = 380;
            context__.validate_dims("data initialization", "nrcens12", "int", context__.to_vec());
            nrcens12 = int(0);
            vals_i__ = context__.vals_i("nrcens12");
            pos__ = 0;
            nrcens12 = vals_i__[pos__++];
            current_statement_begin__ = 382;
            context__.validate_dims("data initialization", "K01", "int", context__.to_vec());
            K01 = int(0);
            vals_i__ = context__.vals_i("K01");
            pos__ = 0;
            K01 = vals_i__[pos__++];
            current_statement_begin__ = 383;
            context__.validate_dims("data initialization", "K02", "int", context__.to_vec());
            K02 = int(0);
            vals_i__ = context__.vals_i("K02");
            pos__ = 0;
            K02 = vals_i__[pos__++];
            current_statement_begin__ = 384;
            context__.validate_dims("data initialization", "K12", "int", context__.to_vec());
            K12 = int(0);
            vals_i__ = context__.vals_i("K12");
            pos__ = 0;
            K12 = vals_i__[pos__++];
            current_statement_begin__ = 387;
            context__.validate_dims("data initialization", "log_crude_event_rate01", "double", context__.to_vec());
            log_crude_event_rate01 = double(0);
            vals_r__ = context__.vals_r("log_crude_event_rate01");
            pos__ = 0;
            log_crude_event_rate01 = vals_r__[pos__++];
            current_statement_begin__ = 388;
            context__.validate_dims("data initialization", "log_crude_event_rate02", "double", context__.to_vec());
            log_crude_event_rate02 = double(0);
            vals_r__ = context__.vals_r("log_crude_event_rate02");
            pos__ = 0;
            log_crude_event_rate02 = vals_r__[pos__++];
            current_statement_begin__ = 389;
            context__.validate_dims("data initialization", "log_crude_event_rate12", "double", context__.to_vec());
            log_crude_event_rate12 = double(0);
            vals_r__ = context__.vals_r("log_crude_event_rate12");
            pos__ = 0;
            log_crude_event_rate12 = vals_r__[pos__++];
            current_statement_begin__ = 392;
            validate_non_negative_index("t_event01", "nevent01", nevent01);
            context__.validate_dims("data initialization", "t_event01", "vector_d", context__.to_vec(nevent01));
            validate_non_negative_index("t_event01", "nevent01", nevent01);
            t_event01 = vector_d(static_cast<Eigen::VectorXd::Index>(nevent01));
            vals_r__ = context__.vals_r("t_event01");
            pos__ = 0;
            size_t t_event01_i_vec_lim__ = nevent01;
            for (size_t i_vec__ = 0; i_vec__ < t_event01_i_vec_lim__; ++i_vec__) {
                t_event01[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 393;
            validate_non_negative_index("t_event02", "nevent02", nevent02);
            context__.validate_dims("data initialization", "t_event02", "vector_d", context__.to_vec(nevent02));
            validate_non_negative_index("t_event02", "nevent02", nevent02);
            t_event02 = vector_d(static_cast<Eigen::VectorXd::Index>(nevent02));
            vals_r__ = context__.vals_r("t_event02");
            pos__ = 0;
            size_t t_event02_i_vec_lim__ = nevent02;
            for (size_t i_vec__ = 0; i_vec__ < t_event02_i_vec_lim__; ++i_vec__) {
                t_event02[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 394;
            validate_non_negative_index("t_event12", "nevent12", nevent12);
            context__.validate_dims("data initialization", "t_event12", "vector_d", context__.to_vec(nevent12));
            validate_non_negative_index("t_event12", "nevent12", nevent12);
            t_event12 = vector_d(static_cast<Eigen::VectorXd::Index>(nevent12));
            vals_r__ = context__.vals_r("t_event12");
            pos__ = 0;
            size_t t_event12_i_vec_lim__ = nevent12;
            for (size_t i_vec__ = 0; i_vec__ < t_event12_i_vec_lim__; ++i_vec__) {
                t_event12[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 396;
            validate_non_negative_index("t_rcens01", "nrcens01", nrcens01);
            context__.validate_dims("data initialization", "t_rcens01", "vector_d", context__.to_vec(nrcens01));
            validate_non_negative_index("t_rcens01", "nrcens01", nrcens01);
            t_rcens01 = vector_d(static_cast<Eigen::VectorXd::Index>(nrcens01));
            vals_r__ = context__.vals_r("t_rcens01");
            pos__ = 0;
            size_t t_rcens01_i_vec_lim__ = nrcens01;
            for (size_t i_vec__ = 0; i_vec__ < t_rcens01_i_vec_lim__; ++i_vec__) {
                t_rcens01[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 397;
            validate_non_negative_index("t_rcens02", "nrcens02", nrcens02);
            context__.validate_dims("data initialization", "t_rcens02", "vector_d", context__.to_vec(nrcens02));
            validate_non_negative_index("t_rcens02", "nrcens02", nrcens02);
            t_rcens02 = vector_d(static_cast<Eigen::VectorXd::Index>(nrcens02));
            vals_r__ = context__.vals_r("t_rcens02");
            pos__ = 0;
            size_t t_rcens02_i_vec_lim__ = nrcens02;
            for (size_t i_vec__ = 0; i_vec__ < t_rcens02_i_vec_lim__; ++i_vec__) {
                t_rcens02[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 398;
            validate_non_negative_index("t_rcens12", "nrcens12", nrcens12);
            context__.validate_dims("data initialization", "t_rcens12", "vector_d", context__.to_vec(nrcens12));
            validate_non_negative_index("t_rcens12", "nrcens12", nrcens12);
            t_rcens12 = vector_d(static_cast<Eigen::VectorXd::Index>(nrcens12));
            vals_r__ = context__.vals_r("t_rcens12");
            pos__ = 0;
            size_t t_rcens12_i_vec_lim__ = nrcens12;
            for (size_t i_vec__ = 0; i_vec__ < t_rcens12_i_vec_lim__; ++i_vec__) {
                t_rcens12[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 400;
            validate_non_negative_index("x_bar01", "K01", K01);
            context__.validate_dims("data initialization", "x_bar01", "vector_d", context__.to_vec(K01));
            validate_non_negative_index("x_bar01", "K01", K01);
            x_bar01 = vector_d(static_cast<Eigen::VectorXd::Index>(K01));
            vals_r__ = context__.vals_r("x_bar01");
            pos__ = 0;
            size_t x_bar01_i_vec_lim__ = K01;
            for (size_t i_vec__ = 0; i_vec__ < x_bar01_i_vec_lim__; ++i_vec__) {
                x_bar01[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 401;
            validate_non_negative_index("x_bar02", "K02", K02);
            context__.validate_dims("data initialization", "x_bar02", "vector_d", context__.to_vec(K02));
            validate_non_negative_index("x_bar02", "K02", K02);
            x_bar02 = vector_d(static_cast<Eigen::VectorXd::Index>(K02));
            vals_r__ = context__.vals_r("x_bar02");
            pos__ = 0;
            size_t x_bar02_i_vec_lim__ = K02;
            for (size_t i_vec__ = 0; i_vec__ < x_bar02_i_vec_lim__; ++i_vec__) {
                x_bar02[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 402;
            validate_non_negative_index("x_bar12", "K12", K12);
            context__.validate_dims("data initialization", "x_bar12", "vector_d", context__.to_vec(K12));
            validate_non_negative_index("x_bar12", "K12", K12);
            x_bar12 = vector_d(static_cast<Eigen::VectorXd::Index>(K12));
            vals_r__ = context__.vals_r("x_bar12");
            pos__ = 0;
            size_t x_bar12_i_vec_lim__ = K12;
            for (size_t i_vec__ = 0; i_vec__ < x_bar12_i_vec_lim__; ++i_vec__) {
                x_bar12[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 404;
            validate_non_negative_index("x_event01", "nevent01", nevent01);
            validate_non_negative_index("x_event01", "K01", K01);
            context__.validate_dims("data initialization", "x_event01", "matrix_d", context__.to_vec(nevent01,K01));
            validate_non_negative_index("x_event01", "nevent01", nevent01);
            validate_non_negative_index("x_event01", "K01", K01);
            x_event01 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent01),static_cast<Eigen::VectorXd::Index>(K01));
            vals_r__ = context__.vals_r("x_event01");
            pos__ = 0;
            size_t x_event01_m_mat_lim__ = nevent01;
            size_t x_event01_n_mat_lim__ = K01;
            for (size_t n_mat__ = 0; n_mat__ < x_event01_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < x_event01_m_mat_lim__; ++m_mat__) {
                    x_event01(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 405;
            validate_non_negative_index("x_event02", "nevent02", nevent02);
            validate_non_negative_index("x_event02", "K02", K02);
            context__.validate_dims("data initialization", "x_event02", "matrix_d", context__.to_vec(nevent02,K02));
            validate_non_negative_index("x_event02", "nevent02", nevent02);
            validate_non_negative_index("x_event02", "K02", K02);
            x_event02 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent02),static_cast<Eigen::VectorXd::Index>(K02));
            vals_r__ = context__.vals_r("x_event02");
            pos__ = 0;
            size_t x_event02_m_mat_lim__ = nevent02;
            size_t x_event02_n_mat_lim__ = K02;
            for (size_t n_mat__ = 0; n_mat__ < x_event02_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < x_event02_m_mat_lim__; ++m_mat__) {
                    x_event02(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 406;
            validate_non_negative_index("x_event12", "nevent12", nevent12);
            validate_non_negative_index("x_event12", "K12", K12);
            context__.validate_dims("data initialization", "x_event12", "matrix_d", context__.to_vec(nevent12,K12));
            validate_non_negative_index("x_event12", "nevent12", nevent12);
            validate_non_negative_index("x_event12", "K12", K12);
            x_event12 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent12),static_cast<Eigen::VectorXd::Index>(K12));
            vals_r__ = context__.vals_r("x_event12");
            pos__ = 0;
            size_t x_event12_m_mat_lim__ = nevent12;
            size_t x_event12_n_mat_lim__ = K12;
            for (size_t n_mat__ = 0; n_mat__ < x_event12_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < x_event12_m_mat_lim__; ++m_mat__) {
                    x_event12(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 408;
            validate_non_negative_index("x_rcens01", "nrcens01", nrcens01);
            validate_non_negative_index("x_rcens01", "K01", K01);
            context__.validate_dims("data initialization", "x_rcens01", "matrix_d", context__.to_vec(nrcens01,K01));
            validate_non_negative_index("x_rcens01", "nrcens01", nrcens01);
            validate_non_negative_index("x_rcens01", "K01", K01);
            x_rcens01 = matrix_d(static_cast<Eigen::VectorXd::Index>(nrcens01),static_cast<Eigen::VectorXd::Index>(K01));
            vals_r__ = context__.vals_r("x_rcens01");
            pos__ = 0;
            size_t x_rcens01_m_mat_lim__ = nrcens01;
            size_t x_rcens01_n_mat_lim__ = K01;
            for (size_t n_mat__ = 0; n_mat__ < x_rcens01_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < x_rcens01_m_mat_lim__; ++m_mat__) {
                    x_rcens01(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 409;
            validate_non_negative_index("x_rcens02", "nrcens02", nrcens02);
            validate_non_negative_index("x_rcens02", "K02", K02);
            context__.validate_dims("data initialization", "x_rcens02", "matrix_d", context__.to_vec(nrcens02,K02));
            validate_non_negative_index("x_rcens02", "nrcens02", nrcens02);
            validate_non_negative_index("x_rcens02", "K02", K02);
            x_rcens02 = matrix_d(static_cast<Eigen::VectorXd::Index>(nrcens02),static_cast<Eigen::VectorXd::Index>(K02));
            vals_r__ = context__.vals_r("x_rcens02");
            pos__ = 0;
            size_t x_rcens02_m_mat_lim__ = nrcens02;
            size_t x_rcens02_n_mat_lim__ = K02;
            for (size_t n_mat__ = 0; n_mat__ < x_rcens02_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < x_rcens02_m_mat_lim__; ++m_mat__) {
                    x_rcens02(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 410;
            validate_non_negative_index("x_rcens12", "nrcens12", nrcens12);
            validate_non_negative_index("x_rcens12", "K12", K12);
            context__.validate_dims("data initialization", "x_rcens12", "matrix_d", context__.to_vec(nrcens12,K12));
            validate_non_negative_index("x_rcens12", "nrcens12", nrcens12);
            validate_non_negative_index("x_rcens12", "K12", K12);
            x_rcens12 = matrix_d(static_cast<Eigen::VectorXd::Index>(nrcens12),static_cast<Eigen::VectorXd::Index>(K12));
            vals_r__ = context__.vals_r("x_rcens12");
            pos__ = 0;
            size_t x_rcens12_m_mat_lim__ = nrcens12;
            size_t x_rcens12_n_mat_lim__ = K12;
            for (size_t n_mat__ = 0; n_mat__ < x_rcens12_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < x_rcens12_m_mat_lim__; ++m_mat__) {
                    x_rcens12(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 413;
            context__.validate_dims("data initialization", "nvars01", "int", context__.to_vec());
            nvars01 = int(0);
            vals_i__ = context__.vals_i("nvars01");
            pos__ = 0;
            nvars01 = vals_i__[pos__++];
            current_statement_begin__ = 414;
            context__.validate_dims("data initialization", "nvars02", "int", context__.to_vec());
            nvars02 = int(0);
            vals_i__ = context__.vals_i("nvars02");
            pos__ = 0;
            nvars02 = vals_i__[pos__++];
            current_statement_begin__ = 415;
            context__.validate_dims("data initialization", "nvars12", "int", context__.to_vec());
            nvars12 = int(0);
            vals_i__ = context__.vals_i("nvars12");
            pos__ = 0;
            nvars12 = vals_i__[pos__++];
            current_statement_begin__ = 417;
            validate_non_negative_index("basis_event01", "nevent01", nevent01);
            validate_non_negative_index("basis_event01", "nvars01", nvars01);
            context__.validate_dims("data initialization", "basis_event01", "matrix_d", context__.to_vec(nevent01,nvars01));
            validate_non_negative_index("basis_event01", "nevent01", nevent01);
            validate_non_negative_index("basis_event01", "nvars01", nvars01);
            basis_event01 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent01),static_cast<Eigen::VectorXd::Index>(nvars01));
            vals_r__ = context__.vals_r("basis_event01");
            pos__ = 0;
            size_t basis_event01_m_mat_lim__ = nevent01;
            size_t basis_event01_n_mat_lim__ = nvars01;
            for (size_t n_mat__ = 0; n_mat__ < basis_event01_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < basis_event01_m_mat_lim__; ++m_mat__) {
                    basis_event01(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 418;
            validate_non_negative_index("basis_event02", "nevent02", nevent02);
            validate_non_negative_index("basis_event02", "nvars02", nvars02);
            context__.validate_dims("data initialization", "basis_event02", "matrix_d", context__.to_vec(nevent02,nvars02));
            validate_non_negative_index("basis_event02", "nevent02", nevent02);
            validate_non_negative_index("basis_event02", "nvars02", nvars02);
            basis_event02 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent02),static_cast<Eigen::VectorXd::Index>(nvars02));
            vals_r__ = context__.vals_r("basis_event02");
            pos__ = 0;
            size_t basis_event02_m_mat_lim__ = nevent02;
            size_t basis_event02_n_mat_lim__ = nvars02;
            for (size_t n_mat__ = 0; n_mat__ < basis_event02_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < basis_event02_m_mat_lim__; ++m_mat__) {
                    basis_event02(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 419;
            validate_non_negative_index("basis_event12", "nevent12", nevent12);
            validate_non_negative_index("basis_event12", "nvars12", nvars12);
            context__.validate_dims("data initialization", "basis_event12", "matrix_d", context__.to_vec(nevent12,nvars12));
            validate_non_negative_index("basis_event12", "nevent12", nevent12);
            validate_non_negative_index("basis_event12", "nvars12", nvars12);
            basis_event12 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent12),static_cast<Eigen::VectorXd::Index>(nvars12));
            vals_r__ = context__.vals_r("basis_event12");
            pos__ = 0;
            size_t basis_event12_m_mat_lim__ = nevent12;
            size_t basis_event12_n_mat_lim__ = nvars12;
            for (size_t n_mat__ = 0; n_mat__ < basis_event12_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < basis_event12_m_mat_lim__; ++m_mat__) {
                    basis_event12(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 421;
            validate_non_negative_index("ibasis_event01", "nevent01", nevent01);
            validate_non_negative_index("ibasis_event01", "nvars01", nvars01);
            context__.validate_dims("data initialization", "ibasis_event01", "matrix_d", context__.to_vec(nevent01,nvars01));
            validate_non_negative_index("ibasis_event01", "nevent01", nevent01);
            validate_non_negative_index("ibasis_event01", "nvars01", nvars01);
            ibasis_event01 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent01),static_cast<Eigen::VectorXd::Index>(nvars01));
            vals_r__ = context__.vals_r("ibasis_event01");
            pos__ = 0;
            size_t ibasis_event01_m_mat_lim__ = nevent01;
            size_t ibasis_event01_n_mat_lim__ = nvars01;
            for (size_t n_mat__ = 0; n_mat__ < ibasis_event01_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < ibasis_event01_m_mat_lim__; ++m_mat__) {
                    ibasis_event01(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 422;
            validate_non_negative_index("ibasis_event02", "nevent02", nevent02);
            validate_non_negative_index("ibasis_event02", "nvars02", nvars02);
            context__.validate_dims("data initialization", "ibasis_event02", "matrix_d", context__.to_vec(nevent02,nvars02));
            validate_non_negative_index("ibasis_event02", "nevent02", nevent02);
            validate_non_negative_index("ibasis_event02", "nvars02", nvars02);
            ibasis_event02 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent02),static_cast<Eigen::VectorXd::Index>(nvars02));
            vals_r__ = context__.vals_r("ibasis_event02");
            pos__ = 0;
            size_t ibasis_event02_m_mat_lim__ = nevent02;
            size_t ibasis_event02_n_mat_lim__ = nvars02;
            for (size_t n_mat__ = 0; n_mat__ < ibasis_event02_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < ibasis_event02_m_mat_lim__; ++m_mat__) {
                    ibasis_event02(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 423;
            validate_non_negative_index("ibasis_event12", "nevent12", nevent12);
            validate_non_negative_index("ibasis_event12", "nvars12", nvars12);
            context__.validate_dims("data initialization", "ibasis_event12", "matrix_d", context__.to_vec(nevent12,nvars12));
            validate_non_negative_index("ibasis_event12", "nevent12", nevent12);
            validate_non_negative_index("ibasis_event12", "nvars12", nvars12);
            ibasis_event12 = matrix_d(static_cast<Eigen::VectorXd::Index>(nevent12),static_cast<Eigen::VectorXd::Index>(nvars12));
            vals_r__ = context__.vals_r("ibasis_event12");
            pos__ = 0;
            size_t ibasis_event12_m_mat_lim__ = nevent12;
            size_t ibasis_event12_n_mat_lim__ = nvars12;
            for (size_t n_mat__ = 0; n_mat__ < ibasis_event12_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < ibasis_event12_m_mat_lim__; ++m_mat__) {
                    ibasis_event12(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 425;
            validate_non_negative_index("ibasis_rcens01", "nrcens01", nrcens01);
            validate_non_negative_index("ibasis_rcens01", "nvars01", nvars01);
            context__.validate_dims("data initialization", "ibasis_rcens01", "matrix_d", context__.to_vec(nrcens01,nvars01));
            validate_non_negative_index("ibasis_rcens01", "nrcens01", nrcens01);
            validate_non_negative_index("ibasis_rcens01", "nvars01", nvars01);
            ibasis_rcens01 = matrix_d(static_cast<Eigen::VectorXd::Index>(nrcens01),static_cast<Eigen::VectorXd::Index>(nvars01));
            vals_r__ = context__.vals_r("ibasis_rcens01");
            pos__ = 0;
            size_t ibasis_rcens01_m_mat_lim__ = nrcens01;
            size_t ibasis_rcens01_n_mat_lim__ = nvars01;
            for (size_t n_mat__ = 0; n_mat__ < ibasis_rcens01_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < ibasis_rcens01_m_mat_lim__; ++m_mat__) {
                    ibasis_rcens01(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 426;
            validate_non_negative_index("ibasis_rcens02", "nrcens02", nrcens02);
            validate_non_negative_index("ibasis_rcens02", "nvars02", nvars02);
            context__.validate_dims("data initialization", "ibasis_rcens02", "matrix_d", context__.to_vec(nrcens02,nvars02));
            validate_non_negative_index("ibasis_rcens02", "nrcens02", nrcens02);
            validate_non_negative_index("ibasis_rcens02", "nvars02", nvars02);
            ibasis_rcens02 = matrix_d(static_cast<Eigen::VectorXd::Index>(nrcens02),static_cast<Eigen::VectorXd::Index>(nvars02));
            vals_r__ = context__.vals_r("ibasis_rcens02");
            pos__ = 0;
            size_t ibasis_rcens02_m_mat_lim__ = nrcens02;
            size_t ibasis_rcens02_n_mat_lim__ = nvars02;
            for (size_t n_mat__ = 0; n_mat__ < ibasis_rcens02_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < ibasis_rcens02_m_mat_lim__; ++m_mat__) {
                    ibasis_rcens02(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 427;
            validate_non_negative_index("ibasis_rcens12", "nrcens12", nrcens12);
            validate_non_negative_index("ibasis_rcens12", "nvars12", nvars12);
            context__.validate_dims("data initialization", "ibasis_rcens12", "matrix_d", context__.to_vec(nrcens12,nvars12));
            validate_non_negative_index("ibasis_rcens12", "nrcens12", nrcens12);
            validate_non_negative_index("ibasis_rcens12", "nvars12", nvars12);
            ibasis_rcens12 = matrix_d(static_cast<Eigen::VectorXd::Index>(nrcens12),static_cast<Eigen::VectorXd::Index>(nvars12));
            vals_r__ = context__.vals_r("ibasis_rcens12");
            pos__ = 0;
            size_t ibasis_rcens12_m_mat_lim__ = nrcens12;
            size_t ibasis_rcens12_n_mat_lim__ = nvars12;
            for (size_t n_mat__ = 0; n_mat__ < ibasis_rcens12_n_mat_lim__; ++n_mat__) {
                for (size_t m_mat__ = 0; m_mat__ < ibasis_rcens12_m_mat_lim__; ++m_mat__) {
                    ibasis_rcens12(m_mat__,n_mat__) = vals_r__[pos__++];
                }
            }
            current_statement_begin__ = 436;
            context__.validate_dims("data initialization", "type01", "int", context__.to_vec());
            type01 = int(0);
            vals_i__ = context__.vals_i("type01");
            pos__ = 0;
            type01 = vals_i__[pos__++];
            current_statement_begin__ = 437;
            context__.validate_dims("data initialization", "type02", "int", context__.to_vec());
            type02 = int(0);
            vals_i__ = context__.vals_i("type02");
            pos__ = 0;
            type02 = vals_i__[pos__++];
            current_statement_begin__ = 438;
            context__.validate_dims("data initialization", "type12", "int", context__.to_vec());
            type12 = int(0);
            vals_i__ = context__.vals_i("type12");
            pos__ = 0;
            type12 = vals_i__[pos__++];
            current_statement_begin__ = 441;
            context__.validate_dims("data initialization", "has_intercept01", "int", context__.to_vec());
            has_intercept01 = int(0);
            vals_i__ = context__.vals_i("has_intercept01");
            pos__ = 0;
            has_intercept01 = vals_i__[pos__++];
            current_statement_begin__ = 442;
            context__.validate_dims("data initialization", "has_intercept02", "int", context__.to_vec());
            has_intercept02 = int(0);
            vals_i__ = context__.vals_i("has_intercept02");
            pos__ = 0;
            has_intercept02 = vals_i__[pos__++];
            current_statement_begin__ = 443;
            context__.validate_dims("data initialization", "has_intercept12", "int", context__.to_vec());
            has_intercept12 = int(0);
            vals_i__ = context__.vals_i("has_intercept12");
            pos__ = 0;
            has_intercept12 = vals_i__[pos__++];
            current_statement_begin__ = 444;
            context__.validate_dims("data initialization", "prior_PD", "int", context__.to_vec());
            prior_PD = int(0);
            vals_i__ = context__.vals_i("prior_PD");
            pos__ = 0;
            prior_PD = vals_i__[pos__++];
            current_statement_begin__ = 450;
            context__.validate_dims("data initialization", "prior_dist01", "int", context__.to_vec());
            prior_dist01 = int(0);
            vals_i__ = context__.vals_i("prior_dist01");
            pos__ = 0;
            prior_dist01 = vals_i__[pos__++];
            current_statement_begin__ = 451;
            context__.validate_dims("data initialization", "prior_dist02", "int", context__.to_vec());
            prior_dist02 = int(0);
            vals_i__ = context__.vals_i("prior_dist02");
            pos__ = 0;
            prior_dist02 = vals_i__[pos__++];
            current_statement_begin__ = 452;
            context__.validate_dims("data initialization", "prior_dist12", "int", context__.to_vec());
            prior_dist12 = int(0);
            vals_i__ = context__.vals_i("prior_dist12");
            pos__ = 0;
            prior_dist12 = vals_i__[pos__++];
            current_statement_begin__ = 454;
            validate_non_negative_index("prior_mean01", "K01", K01);
            context__.validate_dims("data initialization", "prior_mean01", "vector_d", context__.to_vec(K01));
            validate_non_negative_index("prior_mean01", "K01", K01);
            prior_mean01 = vector_d(static_cast<Eigen::VectorXd::Index>(K01));
            vals_r__ = context__.vals_r("prior_mean01");
            pos__ = 0;
            size_t prior_mean01_i_vec_lim__ = K01;
            for (size_t i_vec__ = 0; i_vec__ < prior_mean01_i_vec_lim__; ++i_vec__) {
                prior_mean01[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 455;
            validate_non_negative_index("prior_mean02", "K02", K02);
            context__.validate_dims("data initialization", "prior_mean02", "vector_d", context__.to_vec(K02));
            validate_non_negative_index("prior_mean02", "K02", K02);
            prior_mean02 = vector_d(static_cast<Eigen::VectorXd::Index>(K02));
            vals_r__ = context__.vals_r("prior_mean02");
            pos__ = 0;
            size_t prior_mean02_i_vec_lim__ = K02;
            for (size_t i_vec__ = 0; i_vec__ < prior_mean02_i_vec_lim__; ++i_vec__) {
                prior_mean02[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 456;
            validate_non_negative_index("prior_mean12", "K12", K12);
            context__.validate_dims("data initialization", "prior_mean12", "vector_d", context__.to_vec(K12));
            validate_non_negative_index("prior_mean12", "K12", K12);
            prior_mean12 = vector_d(static_cast<Eigen::VectorXd::Index>(K12));
            vals_r__ = context__.vals_r("prior_mean12");
            pos__ = 0;
            size_t prior_mean12_i_vec_lim__ = K12;
            for (size_t i_vec__ = 0; i_vec__ < prior_mean12_i_vec_lim__; ++i_vec__) {
                prior_mean12[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 457;
            validate_non_negative_index("prior_scale01", "K01", K01);
            context__.validate_dims("data initialization", "prior_scale01", "vector_d", context__.to_vec(K01));
            validate_non_negative_index("prior_scale01", "K01", K01);
            prior_scale01 = vector_d(static_cast<Eigen::VectorXd::Index>(K01));
            vals_r__ = context__.vals_r("prior_scale01");
            pos__ = 0;
            size_t prior_scale01_i_vec_lim__ = K01;
            for (size_t i_vec__ = 0; i_vec__ < prior_scale01_i_vec_lim__; ++i_vec__) {
                prior_scale01[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 458;
            validate_non_negative_index("prior_scale02", "K02", K02);
            context__.validate_dims("data initialization", "prior_scale02", "vector_d", context__.to_vec(K02));
            validate_non_negative_index("prior_scale02", "K02", K02);
            prior_scale02 = vector_d(static_cast<Eigen::VectorXd::Index>(K02));
            vals_r__ = context__.vals_r("prior_scale02");
            pos__ = 0;
            size_t prior_scale02_i_vec_lim__ = K02;
            for (size_t i_vec__ = 0; i_vec__ < prior_scale02_i_vec_lim__; ++i_vec__) {
                prior_scale02[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 459;
            validate_non_negative_index("prior_scale12", "K12", K12);
            context__.validate_dims("data initialization", "prior_scale12", "vector_d", context__.to_vec(K12));
            validate_non_negative_index("prior_scale12", "K12", K12);
            prior_scale12 = vector_d(static_cast<Eigen::VectorXd::Index>(K12));
            vals_r__ = context__.vals_r("prior_scale12");
            pos__ = 0;
            size_t prior_scale12_i_vec_lim__ = K12;
            for (size_t i_vec__ = 0; i_vec__ < prior_scale12_i_vec_lim__; ++i_vec__) {
                prior_scale12[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 465;
            context__.validate_dims("data initialization", "prior_dist_for_intercept01", "int", context__.to_vec());
            prior_dist_for_intercept01 = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_intercept01");
            pos__ = 0;
            prior_dist_for_intercept01 = vals_i__[pos__++];
            current_statement_begin__ = 466;
            context__.validate_dims("data initialization", "prior_dist_for_intercept02", "int", context__.to_vec());
            prior_dist_for_intercept02 = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_intercept02");
            pos__ = 0;
            prior_dist_for_intercept02 = vals_i__[pos__++];
            current_statement_begin__ = 467;
            context__.validate_dims("data initialization", "prior_dist_for_intercept12", "int", context__.to_vec());
            prior_dist_for_intercept12 = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_intercept12");
            pos__ = 0;
            prior_dist_for_intercept12 = vals_i__[pos__++];
            current_statement_begin__ = 470;
            context__.validate_dims("data initialization", "prior_mean_for_intercept01", "double", context__.to_vec());
            prior_mean_for_intercept01 = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_intercept01");
            pos__ = 0;
            prior_mean_for_intercept01 = vals_r__[pos__++];
            current_statement_begin__ = 471;
            context__.validate_dims("data initialization", "prior_scale_for_intercept01", "double", context__.to_vec());
            prior_scale_for_intercept01 = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_intercept01");
            pos__ = 0;
            prior_scale_for_intercept01 = vals_r__[pos__++];
            current_statement_begin__ = 472;
            context__.validate_dims("data initialization", "prior_mean_for_intercept02", "double", context__.to_vec());
            prior_mean_for_intercept02 = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_intercept02");
            pos__ = 0;
            prior_mean_for_intercept02 = vals_r__[pos__++];
            current_statement_begin__ = 473;
            context__.validate_dims("data initialization", "prior_scale_for_intercept02", "double", context__.to_vec());
            prior_scale_for_intercept02 = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_intercept02");
            pos__ = 0;
            prior_scale_for_intercept02 = vals_r__[pos__++];
            current_statement_begin__ = 474;
            context__.validate_dims("data initialization", "prior_mean_for_intercept12", "double", context__.to_vec());
            prior_mean_for_intercept12 = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_intercept12");
            pos__ = 0;
            prior_mean_for_intercept12 = vals_r__[pos__++];
            current_statement_begin__ = 475;
            context__.validate_dims("data initialization", "prior_scale_for_intercept12", "double", context__.to_vec());
            prior_scale_for_intercept12 = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_intercept12");
            pos__ = 0;
            prior_scale_for_intercept12 = vals_r__[pos__++];
            current_statement_begin__ = 482;
            context__.validate_dims("data initialization", "prior_dist_for_aux01", "int", context__.to_vec());
            prior_dist_for_aux01 = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_aux01");
            pos__ = 0;
            prior_dist_for_aux01 = vals_i__[pos__++];
            current_statement_begin__ = 483;
            context__.validate_dims("data initialization", "prior_dist_for_aux02", "int", context__.to_vec());
            prior_dist_for_aux02 = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_aux02");
            pos__ = 0;
            prior_dist_for_aux02 = vals_i__[pos__++];
            current_statement_begin__ = 484;
            context__.validate_dims("data initialization", "prior_dist_for_aux12", "int", context__.to_vec());
            prior_dist_for_aux12 = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_aux12");
            pos__ = 0;
            prior_dist_for_aux12 = vals_i__[pos__++];
            current_statement_begin__ = 487;
            validate_non_negative_index("prior_scale_for_aux01", "nvars01", nvars01);
            context__.validate_dims("data initialization", "prior_scale_for_aux01", "vector_d", context__.to_vec(nvars01));
            validate_non_negative_index("prior_scale_for_aux01", "nvars01", nvars01);
            prior_scale_for_aux01 = vector_d(static_cast<Eigen::VectorXd::Index>(nvars01));
            vals_r__ = context__.vals_r("prior_scale_for_aux01");
            pos__ = 0;
            size_t prior_scale_for_aux01_i_vec_lim__ = nvars01;
            for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_aux01_i_vec_lim__; ++i_vec__) {
                prior_scale_for_aux01[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 488;
            validate_non_negative_index("prior_scale_for_aux02", "nvars02", nvars02);
            context__.validate_dims("data initialization", "prior_scale_for_aux02", "vector_d", context__.to_vec(nvars02));
            validate_non_negative_index("prior_scale_for_aux02", "nvars02", nvars02);
            prior_scale_for_aux02 = vector_d(static_cast<Eigen::VectorXd::Index>(nvars02));
            vals_r__ = context__.vals_r("prior_scale_for_aux02");
            pos__ = 0;
            size_t prior_scale_for_aux02_i_vec_lim__ = nvars02;
            for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_aux02_i_vec_lim__; ++i_vec__) {
                prior_scale_for_aux02[i_vec__] = vals_r__[pos__++];
            }
            current_statement_begin__ = 489;
            validate_non_negative_index("prior_scale_for_aux12", "nvars12", nvars12);
            context__.validate_dims("data initialization", "prior_scale_for_aux12", "vector_d", context__.to_vec(nvars12));
            validate_non_negative_index("prior_scale_for_aux12", "nvars12", nvars12);
            prior_scale_for_aux12 = vector_d(static_cast<Eigen::VectorXd::Index>(nvars12));
            vals_r__ = context__.vals_r("prior_scale_for_aux12");
            pos__ = 0;
            size_t prior_scale_for_aux12_i_vec_lim__ = nvars12;
            for (size_t i_vec__ = 0; i_vec__ < prior_scale_for_aux12_i_vec_lim__; ++i_vec__) {
                prior_scale_for_aux12[i_vec__] = vals_r__[pos__++];
            }

            // validate, data variables
            current_statement_begin__ = 374;
            check_greater_or_equal(function__,"nevent01",nevent01,0);
            current_statement_begin__ = 375;
            check_greater_or_equal(function__,"nevent02",nevent02,0);
            current_statement_begin__ = 376;
            check_greater_or_equal(function__,"nevent12",nevent12,0);
            current_statement_begin__ = 378;
            check_greater_or_equal(function__,"nrcens01",nrcens01,0);
            current_statement_begin__ = 379;
            check_greater_or_equal(function__,"nrcens02",nrcens02,0);
            current_statement_begin__ = 380;
            check_greater_or_equal(function__,"nrcens12",nrcens12,0);
            current_statement_begin__ = 382;
            check_greater_or_equal(function__,"K01",K01,0);
            current_statement_begin__ = 383;
            check_greater_or_equal(function__,"K02",K02,0);
            current_statement_begin__ = 384;
            check_greater_or_equal(function__,"K12",K12,0);
            current_statement_begin__ = 387;
            current_statement_begin__ = 388;
            current_statement_begin__ = 389;
            current_statement_begin__ = 392;
            current_statement_begin__ = 393;
            current_statement_begin__ = 394;
            current_statement_begin__ = 396;
            current_statement_begin__ = 397;
            current_statement_begin__ = 398;
            current_statement_begin__ = 400;
            current_statement_begin__ = 401;
            current_statement_begin__ = 402;
            current_statement_begin__ = 404;
            current_statement_begin__ = 405;
            current_statement_begin__ = 406;
            current_statement_begin__ = 408;
            current_statement_begin__ = 409;
            current_statement_begin__ = 410;
            current_statement_begin__ = 413;
            check_greater_or_equal(function__,"nvars01",nvars01,0);
            current_statement_begin__ = 414;
            check_greater_or_equal(function__,"nvars02",nvars02,0);
            current_statement_begin__ = 415;
            check_greater_or_equal(function__,"nvars12",nvars12,0);
            current_statement_begin__ = 417;
            current_statement_begin__ = 418;
            current_statement_begin__ = 419;
            current_statement_begin__ = 421;
            current_statement_begin__ = 422;
            current_statement_begin__ = 423;
            current_statement_begin__ = 425;
            current_statement_begin__ = 426;
            current_statement_begin__ = 427;
            current_statement_begin__ = 436;
            check_greater_or_equal(function__,"type01",type01,1);
            check_less_or_equal(function__,"type01",type01,7);
            current_statement_begin__ = 437;
            check_greater_or_equal(function__,"type02",type02,1);
            check_less_or_equal(function__,"type02",type02,7);
            current_statement_begin__ = 438;
            check_greater_or_equal(function__,"type12",type12,1);
            check_less_or_equal(function__,"type12",type12,7);
            current_statement_begin__ = 441;
            check_greater_or_equal(function__,"has_intercept01",has_intercept01,0);
            check_less_or_equal(function__,"has_intercept01",has_intercept01,1);
            current_statement_begin__ = 442;
            check_greater_or_equal(function__,"has_intercept02",has_intercept02,0);
            check_less_or_equal(function__,"has_intercept02",has_intercept02,1);
            current_statement_begin__ = 443;
            check_greater_or_equal(function__,"has_intercept12",has_intercept12,0);
            check_less_or_equal(function__,"has_intercept12",has_intercept12,1);
            current_statement_begin__ = 444;
            check_greater_or_equal(function__,"prior_PD",prior_PD,0);
            check_less_or_equal(function__,"prior_PD",prior_PD,1);
            current_statement_begin__ = 450;
            check_greater_or_equal(function__,"prior_dist01",prior_dist01,0);
            check_less_or_equal(function__,"prior_dist01",prior_dist01,2);
            current_statement_begin__ = 451;
            check_greater_or_equal(function__,"prior_dist02",prior_dist02,0);
            check_less_or_equal(function__,"prior_dist02",prior_dist02,2);
            current_statement_begin__ = 452;
            check_greater_or_equal(function__,"prior_dist12",prior_dist12,0);
            check_less_or_equal(function__,"prior_dist12",prior_dist12,2);
            current_statement_begin__ = 454;
            current_statement_begin__ = 455;
            current_statement_begin__ = 456;
            current_statement_begin__ = 457;
            check_greater_or_equal(function__,"prior_scale01",prior_scale01,0);
            current_statement_begin__ = 458;
            check_greater_or_equal(function__,"prior_scale02",prior_scale02,0);
            current_statement_begin__ = 459;
            check_greater_or_equal(function__,"prior_scale12",prior_scale12,0);
            current_statement_begin__ = 465;
            check_greater_or_equal(function__,"prior_dist_for_intercept01",prior_dist_for_intercept01,0);
            check_less_or_equal(function__,"prior_dist_for_intercept01",prior_dist_for_intercept01,2);
            current_statement_begin__ = 466;
            check_greater_or_equal(function__,"prior_dist_for_intercept02",prior_dist_for_intercept02,0);
            check_less_or_equal(function__,"prior_dist_for_intercept02",prior_dist_for_intercept02,2);
            current_statement_begin__ = 467;
            check_greater_or_equal(function__,"prior_dist_for_intercept12",prior_dist_for_intercept12,0);
            check_less_or_equal(function__,"prior_dist_for_intercept12",prior_dist_for_intercept12,2);
            current_statement_begin__ = 470;
            current_statement_begin__ = 471;
            check_greater_or_equal(function__,"prior_scale_for_intercept01",prior_scale_for_intercept01,0);
            current_statement_begin__ = 472;
            current_statement_begin__ = 473;
            check_greater_or_equal(function__,"prior_scale_for_intercept02",prior_scale_for_intercept02,0);
            current_statement_begin__ = 474;
            current_statement_begin__ = 475;
            check_greater_or_equal(function__,"prior_scale_for_intercept12",prior_scale_for_intercept12,0);
            current_statement_begin__ = 482;
            check_greater_or_equal(function__,"prior_dist_for_aux01",prior_dist_for_aux01,0);
            check_less_or_equal(function__,"prior_dist_for_aux01",prior_dist_for_aux01,3);
            current_statement_begin__ = 483;
            check_greater_or_equal(function__,"prior_dist_for_aux02",prior_dist_for_aux02,0);
            check_less_or_equal(function__,"prior_dist_for_aux02",prior_dist_for_aux02,3);
            current_statement_begin__ = 484;
            check_greater_or_equal(function__,"prior_dist_for_aux12",prior_dist_for_aux12,0);
            check_less_or_equal(function__,"prior_dist_for_aux12",prior_dist_for_aux12,3);
            current_statement_begin__ = 487;
            check_greater_or_equal(function__,"prior_scale_for_aux01",prior_scale_for_aux01,0);
            current_statement_begin__ = 488;
            check_greater_or_equal(function__,"prior_scale_for_aux02",prior_scale_for_aux02,0);
            current_statement_begin__ = 489;
            check_greater_or_equal(function__,"prior_scale_for_aux12",prior_scale_for_aux12,0);
            // initialize data variables


            // validate transformed data

            // validate, set parameter ranges
            num_params_r__ = 0U;
            param_ranges_i__.clear();
            current_statement_begin__ = 496;
            validate_non_negative_index("z_beta01", "K01", K01);
            num_params_r__ += K01;
            current_statement_begin__ = 497;
            validate_non_negative_index("z_beta02", "K02", K02);
            num_params_r__ += K02;
            current_statement_begin__ = 498;
            validate_non_negative_index("z_beta12", "K12", K12);
            num_params_r__ += K12;
            current_statement_begin__ = 502;
            validate_non_negative_index("z_coefs01", "nvars01", nvars01);
            num_params_r__ += nvars01;
            current_statement_begin__ = 503;
            validate_non_negative_index("z_coefs02", "nvars02", nvars02);
            num_params_r__ += nvars02;
            current_statement_begin__ = 504;
            validate_non_negative_index("z_coefs12", "nvars12", nvars12);
            num_params_r__ += nvars12;
            current_statement_begin__ = 507;
            validate_non_negative_index("gamma01", "has_intercept01", has_intercept01);
            num_params_r__ += has_intercept01;
            current_statement_begin__ = 508;
            validate_non_negative_index("gamma02", "has_intercept02", has_intercept02);
            num_params_r__ += has_intercept02;
            current_statement_begin__ = 509;
            validate_non_negative_index("gamma12", "has_intercept12", has_intercept12);
            num_params_r__ += has_intercept12;
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }

    ~model_MS() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        if (!(context__.contains_r("z_beta01")))
            throw std::runtime_error("variable z_beta01 missing");
        vals_r__ = context__.vals_r("z_beta01");
        pos__ = 0U;
        validate_non_negative_index("z_beta01", "K01", K01);
        context__.validate_dims("initialization", "z_beta01", "vector_d", context__.to_vec(K01));
        vector_d z_beta01(static_cast<Eigen::VectorXd::Index>(K01));
        for (int j1__ = 0U; j1__ < K01; ++j1__)
            z_beta01(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta01);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta01: ") + e.what());
        }

        if (!(context__.contains_r("z_beta02")))
            throw std::runtime_error("variable z_beta02 missing");
        vals_r__ = context__.vals_r("z_beta02");
        pos__ = 0U;
        validate_non_negative_index("z_beta02", "K02", K02);
        context__.validate_dims("initialization", "z_beta02", "vector_d", context__.to_vec(K02));
        vector_d z_beta02(static_cast<Eigen::VectorXd::Index>(K02));
        for (int j1__ = 0U; j1__ < K02; ++j1__)
            z_beta02(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta02);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta02: ") + e.what());
        }

        if (!(context__.contains_r("z_beta12")))
            throw std::runtime_error("variable z_beta12 missing");
        vals_r__ = context__.vals_r("z_beta12");
        pos__ = 0U;
        validate_non_negative_index("z_beta12", "K12", K12);
        context__.validate_dims("initialization", "z_beta12", "vector_d", context__.to_vec(K12));
        vector_d z_beta12(static_cast<Eigen::VectorXd::Index>(K12));
        for (int j1__ = 0U; j1__ < K12; ++j1__)
            z_beta12(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_unconstrain(z_beta12);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_beta12: ") + e.what());
        }

        if (!(context__.contains_r("z_coefs01")))
            throw std::runtime_error("variable z_coefs01 missing");
        vals_r__ = context__.vals_r("z_coefs01");
        pos__ = 0U;
        validate_non_negative_index("z_coefs01", "nvars01", nvars01);
        context__.validate_dims("initialization", "z_coefs01", "vector_d", context__.to_vec(nvars01));
        vector_d z_coefs01(static_cast<Eigen::VectorXd::Index>(nvars01));
        for (int j1__ = 0U; j1__ < nvars01; ++j1__)
            z_coefs01(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,z_coefs01);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_coefs01: ") + e.what());
        }

        if (!(context__.contains_r("z_coefs02")))
            throw std::runtime_error("variable z_coefs02 missing");
        vals_r__ = context__.vals_r("z_coefs02");
        pos__ = 0U;
        validate_non_negative_index("z_coefs02", "nvars02", nvars02);
        context__.validate_dims("initialization", "z_coefs02", "vector_d", context__.to_vec(nvars02));
        vector_d z_coefs02(static_cast<Eigen::VectorXd::Index>(nvars02));
        for (int j1__ = 0U; j1__ < nvars02; ++j1__)
            z_coefs02(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,z_coefs02);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_coefs02: ") + e.what());
        }

        if (!(context__.contains_r("z_coefs12")))
            throw std::runtime_error("variable z_coefs12 missing");
        vals_r__ = context__.vals_r("z_coefs12");
        pos__ = 0U;
        validate_non_negative_index("z_coefs12", "nvars12", nvars12);
        context__.validate_dims("initialization", "z_coefs12", "vector_d", context__.to_vec(nvars12));
        vector_d z_coefs12(static_cast<Eigen::VectorXd::Index>(nvars12));
        for (int j1__ = 0U; j1__ < nvars12; ++j1__)
            z_coefs12(j1__) = vals_r__[pos__++];
        try {
            writer__.vector_lb_unconstrain(0,z_coefs12);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable z_coefs12: ") + e.what());
        }

        if (!(context__.contains_r("gamma01")))
            throw std::runtime_error("variable gamma01 missing");
        vals_r__ = context__.vals_r("gamma01");
        pos__ = 0U;
        validate_non_negative_index("gamma01", "has_intercept01", has_intercept01);
        context__.validate_dims("initialization", "gamma01", "double", context__.to_vec(has_intercept01));
        std::vector<double> gamma01(has_intercept01,double(0));
        for (int i0__ = 0U; i0__ < has_intercept01; ++i0__)
            gamma01[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept01; ++i0__)
            try {
            writer__.scalar_unconstrain(gamma01[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma01: ") + e.what());
        }

        if (!(context__.contains_r("gamma02")))
            throw std::runtime_error("variable gamma02 missing");
        vals_r__ = context__.vals_r("gamma02");
        pos__ = 0U;
        validate_non_negative_index("gamma02", "has_intercept02", has_intercept02);
        context__.validate_dims("initialization", "gamma02", "double", context__.to_vec(has_intercept02));
        std::vector<double> gamma02(has_intercept02,double(0));
        for (int i0__ = 0U; i0__ < has_intercept02; ++i0__)
            gamma02[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept02; ++i0__)
            try {
            writer__.scalar_unconstrain(gamma02[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma02: ") + e.what());
        }

        if (!(context__.contains_r("gamma12")))
            throw std::runtime_error("variable gamma12 missing");
        vals_r__ = context__.vals_r("gamma12");
        pos__ = 0U;
        validate_non_negative_index("gamma12", "has_intercept12", has_intercept12);
        context__.validate_dims("initialization", "gamma12", "double", context__.to_vec(has_intercept12));
        std::vector<double> gamma12(has_intercept12,double(0));
        for (int i0__ = 0U; i0__ < has_intercept12; ++i0__)
            gamma12[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < has_intercept12; ++i0__)
            try {
            writer__.scalar_unconstrain(gamma12[i0__]);
        } catch (const std::exception& e) { 
            throw std::runtime_error(std::string("Error transforming variable gamma12: ") + e.what());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        typedef T__ local_scalar_t__;

        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        try {
            // model parameters
            stan::io::reader<local_scalar_t__> in__(params_r__,params_i__);

            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  z_beta01;
            (void) z_beta01;  // dummy to suppress unused var warning
            if (jacobian__)
                z_beta01 = in__.vector_constrain(K01,lp__);
            else
                z_beta01 = in__.vector_constrain(K01);

            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  z_beta02;
            (void) z_beta02;  // dummy to suppress unused var warning
            if (jacobian__)
                z_beta02 = in__.vector_constrain(K02,lp__);
            else
                z_beta02 = in__.vector_constrain(K02);

            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  z_beta12;
            (void) z_beta12;  // dummy to suppress unused var warning
            if (jacobian__)
                z_beta12 = in__.vector_constrain(K12,lp__);
            else
                z_beta12 = in__.vector_constrain(K12);

            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  z_coefs01;
            (void) z_coefs01;  // dummy to suppress unused var warning
            if (jacobian__)
                z_coefs01 = in__.vector_lb_constrain(0,nvars01,lp__);
            else
                z_coefs01 = in__.vector_lb_constrain(0,nvars01);

            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  z_coefs02;
            (void) z_coefs02;  // dummy to suppress unused var warning
            if (jacobian__)
                z_coefs02 = in__.vector_lb_constrain(0,nvars02,lp__);
            else
                z_coefs02 = in__.vector_lb_constrain(0,nvars02);

            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  z_coefs12;
            (void) z_coefs12;  // dummy to suppress unused var warning
            if (jacobian__)
                z_coefs12 = in__.vector_lb_constrain(0,nvars12,lp__);
            else
                z_coefs12 = in__.vector_lb_constrain(0,nvars12);

            vector<local_scalar_t__> gamma01;
            size_t dim_gamma01_0__ = has_intercept01;
            gamma01.reserve(dim_gamma01_0__);
            for (size_t k_0__ = 0; k_0__ < dim_gamma01_0__; ++k_0__) {
                if (jacobian__)
                    gamma01.push_back(in__.scalar_constrain(lp__));
                else
                    gamma01.push_back(in__.scalar_constrain());
            }

            vector<local_scalar_t__> gamma02;
            size_t dim_gamma02_0__ = has_intercept02;
            gamma02.reserve(dim_gamma02_0__);
            for (size_t k_0__ = 0; k_0__ < dim_gamma02_0__; ++k_0__) {
                if (jacobian__)
                    gamma02.push_back(in__.scalar_constrain(lp__));
                else
                    gamma02.push_back(in__.scalar_constrain());
            }

            vector<local_scalar_t__> gamma12;
            size_t dim_gamma12_0__ = has_intercept12;
            gamma12.reserve(dim_gamma12_0__);
            for (size_t k_0__ = 0; k_0__ < dim_gamma12_0__; ++k_0__) {
                if (jacobian__)
                    gamma12.push_back(in__.scalar_constrain(lp__));
                else
                    gamma12.push_back(in__.scalar_constrain());
            }


            // transformed parameters
            current_statement_begin__ = 515;
            validate_non_negative_index("beta01", "K01", K01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta01(static_cast<Eigen::VectorXd::Index>(K01));
            (void) beta01;  // dummy to suppress unused var warning

            stan::math::initialize(beta01, DUMMY_VAR__);
            stan::math::fill(beta01,DUMMY_VAR__);
            current_statement_begin__ = 516;
            validate_non_negative_index("beta02", "K02", K02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta02(static_cast<Eigen::VectorXd::Index>(K02));
            (void) beta02;  // dummy to suppress unused var warning

            stan::math::initialize(beta02, DUMMY_VAR__);
            stan::math::fill(beta02,DUMMY_VAR__);
            current_statement_begin__ = 517;
            validate_non_negative_index("beta12", "K12", K12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta12(static_cast<Eigen::VectorXd::Index>(K12));
            (void) beta12;  // dummy to suppress unused var warning

            stan::math::initialize(beta12, DUMMY_VAR__);
            stan::math::fill(beta12,DUMMY_VAR__);
            current_statement_begin__ = 520;
            validate_non_negative_index("coefs01", "nvars01", nvars01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  coefs01(static_cast<Eigen::VectorXd::Index>(nvars01));
            (void) coefs01;  // dummy to suppress unused var warning

            stan::math::initialize(coefs01, DUMMY_VAR__);
            stan::math::fill(coefs01,DUMMY_VAR__);
            current_statement_begin__ = 521;
            validate_non_negative_index("coefs02", "nvars02", nvars02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  coefs02(static_cast<Eigen::VectorXd::Index>(nvars02));
            (void) coefs02;  // dummy to suppress unused var warning

            stan::math::initialize(coefs02, DUMMY_VAR__);
            stan::math::fill(coefs02,DUMMY_VAR__);
            current_statement_begin__ = 522;
            validate_non_negative_index("coefs12", "nvars12", nvars12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  coefs12(static_cast<Eigen::VectorXd::Index>(nvars12));
            (void) coefs12;  // dummy to suppress unused var warning

            stan::math::initialize(coefs12, DUMMY_VAR__);
            stan::math::fill(coefs12,DUMMY_VAR__);


            current_statement_begin__ = 525;
            if (as_bool(logical_gt(K01,0))) {

                current_statement_begin__ = 526;
                stan::math::assign(beta01, make_beta(z_beta01,prior_dist01,prior_mean01,prior_scale01, pstream__));
            }
            current_statement_begin__ = 529;
            if (as_bool(logical_gt(K02,0))) {

                current_statement_begin__ = 530;
                stan::math::assign(beta02, make_beta(z_beta02,prior_dist02,prior_mean02,prior_scale02, pstream__));
            }
            current_statement_begin__ = 533;
            if (as_bool(logical_gt(K12,0))) {

                current_statement_begin__ = 534;
                stan::math::assign(beta12, make_beta(z_beta12,prior_dist12,prior_mean12,prior_scale12, pstream__));
            }
            current_statement_begin__ = 539;
            if (as_bool(logical_gt(nvars01,0))) {

                current_statement_begin__ = 540;
                stan::math::assign(coefs01, elt_multiply(z_coefs01,prior_scale_for_aux01));
            }
            current_statement_begin__ = 542;
            if (as_bool(logical_gt(nvars02,0))) {

                current_statement_begin__ = 543;
                stan::math::assign(coefs02, elt_multiply(z_coefs02,prior_scale_for_aux02));
            }
            current_statement_begin__ = 545;
            if (as_bool(logical_gt(nvars12,0))) {

                current_statement_begin__ = 546;
                stan::math::assign(coefs12, elt_multiply(z_coefs12,prior_scale_for_aux12));
            }

            // validate transformed parameters
            for (int i0__ = 0; i0__ < K01; ++i0__) {
                if (stan::math::is_uninitialized(beta01(i0__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: beta01" << '[' << i0__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }
            for (int i0__ = 0; i0__ < K02; ++i0__) {
                if (stan::math::is_uninitialized(beta02(i0__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: beta02" << '[' << i0__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }
            for (int i0__ = 0; i0__ < K12; ++i0__) {
                if (stan::math::is_uninitialized(beta12(i0__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: beta12" << '[' << i0__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }
            for (int i0__ = 0; i0__ < nvars01; ++i0__) {
                if (stan::math::is_uninitialized(coefs01(i0__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: coefs01" << '[' << i0__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }
            for (int i0__ = 0; i0__ < nvars02; ++i0__) {
                if (stan::math::is_uninitialized(coefs02(i0__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: coefs02" << '[' << i0__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }
            for (int i0__ = 0; i0__ < nvars12; ++i0__) {
                if (stan::math::is_uninitialized(coefs12(i0__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: coefs12" << '[' << i0__ << ']';
                    throw std::runtime_error(msg__.str());
                }
            }

            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning
            current_statement_begin__ = 515;
            current_statement_begin__ = 516;
            current_statement_begin__ = 517;
            current_statement_begin__ = 520;
            current_statement_begin__ = 521;
            current_statement_begin__ = 522;

            // model body
            {
            current_statement_begin__ = 552;
            validate_non_negative_index("eta_rcens01", "nrcens01", nrcens01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  eta_rcens01(static_cast<Eigen::VectorXd::Index>(nrcens01));
            (void) eta_rcens01;  // dummy to suppress unused var warning

            stan::math::initialize(eta_rcens01, DUMMY_VAR__);
            stan::math::fill(eta_rcens01,DUMMY_VAR__);
            current_statement_begin__ = 553;
            validate_non_negative_index("eta_event01", "nevent01", nevent01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  eta_event01(static_cast<Eigen::VectorXd::Index>(nevent01));
            (void) eta_event01;  // dummy to suppress unused var warning

            stan::math::initialize(eta_event01, DUMMY_VAR__);
            stan::math::fill(eta_event01,DUMMY_VAR__);
            current_statement_begin__ = 555;
            validate_non_negative_index("eta_event02", "nevent02", nevent02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  eta_event02(static_cast<Eigen::VectorXd::Index>(nevent02));
            (void) eta_event02;  // dummy to suppress unused var warning

            stan::math::initialize(eta_event02, DUMMY_VAR__);
            stan::math::fill(eta_event02,DUMMY_VAR__);
            current_statement_begin__ = 556;
            validate_non_negative_index("eta_rcens02", "nrcens02", nrcens02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  eta_rcens02(static_cast<Eigen::VectorXd::Index>(nrcens02));
            (void) eta_rcens02;  // dummy to suppress unused var warning

            stan::math::initialize(eta_rcens02, DUMMY_VAR__);
            stan::math::fill(eta_rcens02,DUMMY_VAR__);
            current_statement_begin__ = 558;
            validate_non_negative_index("eta_rcens12", "nrcens12", nrcens12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  eta_rcens12(static_cast<Eigen::VectorXd::Index>(nrcens12));
            (void) eta_rcens12;  // dummy to suppress unused var warning

            stan::math::initialize(eta_rcens12, DUMMY_VAR__);
            stan::math::fill(eta_rcens12,DUMMY_VAR__);
            current_statement_begin__ = 559;
            validate_non_negative_index("eta_event12", "nevent12", nevent12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  eta_event12(static_cast<Eigen::VectorXd::Index>(nevent12));
            (void) eta_event12;  // dummy to suppress unused var warning

            stan::math::initialize(eta_event12, DUMMY_VAR__);
            stan::math::fill(eta_event12,DUMMY_VAR__);


            current_statement_begin__ = 562;
            if (as_bool(logical_gt(K01,0))) {

                current_statement_begin__ = 563;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 563;
                    stan::math::assign(eta_event01, multiply(x_event01,beta01));
                }
                current_statement_begin__ = 564;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 564;
                    stan::math::assign(eta_rcens01, multiply(x_rcens01,beta01));
                }
            } else {

                current_statement_begin__ = 566;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 566;
                    stan::math::assign(eta_event01, rep_vector(0.0,nevent01));
                }
                current_statement_begin__ = 567;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 567;
                    stan::math::assign(eta_rcens01, rep_vector(0.0,nrcens01));
                }
            }
            current_statement_begin__ = 570;
            if (as_bool(logical_gt(K02,0))) {

                current_statement_begin__ = 571;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 571;
                    stan::math::assign(eta_event02, multiply(x_event02,beta02));
                }
                current_statement_begin__ = 572;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 572;
                    stan::math::assign(eta_rcens02, multiply(x_rcens02,beta02));
                }
            } else {

                current_statement_begin__ = 574;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 574;
                    stan::math::assign(eta_event02, rep_vector(0.0,nevent02));
                }
                current_statement_begin__ = 575;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 575;
                    stan::math::assign(eta_rcens02, rep_vector(0.0,nrcens02));
                }
            }
            current_statement_begin__ = 578;
            if (as_bool(logical_gt(K12,0))) {

                current_statement_begin__ = 579;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 579;
                    stan::math::assign(eta_event12, multiply(x_event12,beta12));
                }
                current_statement_begin__ = 580;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 580;
                    stan::math::assign(eta_rcens12, multiply(x_rcens12,beta12));
                }
            } else {

                current_statement_begin__ = 582;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 582;
                    stan::math::assign(eta_event12, rep_vector(0.0,nevent12));
                }
                current_statement_begin__ = 583;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 583;
                    stan::math::assign(eta_rcens12, rep_vector(0.0,nrcens12));
                }
            }
            current_statement_begin__ = 587;
            if (as_bool(logical_eq(has_intercept01,1))) {

                current_statement_begin__ = 588;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 588;
                    stan::math::assign(eta_event01, add(eta_event01, get_base1(gamma01,1,"gamma01",1)));
                }
                current_statement_begin__ = 589;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 589;
                    stan::math::assign(eta_rcens01, add(eta_rcens01, get_base1(gamma01,1,"gamma01",1)));
                }
            }
            current_statement_begin__ = 591;
            if (as_bool(logical_eq(has_intercept02,1))) {

                current_statement_begin__ = 592;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 592;
                    stan::math::assign(eta_event02, add(eta_event02, get_base1(gamma02,1,"gamma02",1)));
                }
                current_statement_begin__ = 593;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 593;
                    stan::math::assign(eta_rcens02, add(eta_rcens02, get_base1(gamma02,1,"gamma02",1)));
                }
            }
            current_statement_begin__ = 595;
            if (as_bool(logical_eq(has_intercept12,1))) {

                current_statement_begin__ = 596;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 596;
                    stan::math::assign(eta_event12, add(eta_event12, get_base1(gamma12,1,"gamma12",1)));
                }
                current_statement_begin__ = 597;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 597;
                    stan::math::assign(eta_rcens12, add(eta_rcens12, get_base1(gamma12,1,"gamma12",1)));
                }
            }
            current_statement_begin__ = 601;
            if (as_bool(logical_gt(nevent01,0))) {
                current_statement_begin__ = 601;
                stan::math::assign(eta_event01, add(eta_event01, log_crude_event_rate01));
            }
            current_statement_begin__ = 602;
            if (as_bool(logical_gt(nrcens01,0))) {
                current_statement_begin__ = 602;
                stan::math::assign(eta_rcens01, add(eta_rcens01, log_crude_event_rate01));
            }
            current_statement_begin__ = 604;
            if (as_bool(logical_gt(nevent02,0))) {
                current_statement_begin__ = 604;
                stan::math::assign(eta_event02, add(eta_event02, log_crude_event_rate02));
            }
            current_statement_begin__ = 605;
            if (as_bool(logical_gt(nrcens02,0))) {
                current_statement_begin__ = 605;
                stan::math::assign(eta_rcens02, add(eta_rcens02, log_crude_event_rate02));
            }
            current_statement_begin__ = 607;
            if (as_bool(logical_gt(nevent12,0))) {
                current_statement_begin__ = 607;
                stan::math::assign(eta_event12, add(eta_event12, log_crude_event_rate12));
            }
            current_statement_begin__ = 608;
            if (as_bool(logical_gt(nrcens12,0))) {
                current_statement_begin__ = 608;
                stan::math::assign(eta_rcens12, add(eta_rcens12, log_crude_event_rate12));
            }
            current_statement_begin__ = 610;
            if (as_bool(logical_eq(type01,1))) {
                {
                current_statement_begin__ = 611;
                local_scalar_t__ shape01;
                (void) shape01;  // dummy to suppress unused var warning

                stan::math::initialize(shape01, DUMMY_VAR__);
                stan::math::fill(shape01,DUMMY_VAR__);
                stan::math::assign(shape01,get_base1(coefs01,1,"coefs01",1));


                current_statement_begin__ = 612;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 612;
                    lp_accum__.add(weibull_log_haz(eta_event01,t_event01,shape01, pstream__));
                }
                current_statement_begin__ = 613;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 613;
                    lp_accum__.add(weibull_log_surv(eta_event01,t_event01,shape01, pstream__));
                }
                current_statement_begin__ = 614;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 614;
                    lp_accum__.add(weibull_log_surv(eta_rcens01,t_rcens01,shape01, pstream__));
                }
                }
            } else if (as_bool(logical_eq(type01,4))) {

                current_statement_begin__ = 616;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 616;
                    lp_accum__.add(mspline_log_surv(eta_rcens01,ibasis_rcens01,coefs01, pstream__));
                }
                current_statement_begin__ = 617;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 617;
                    lp_accum__.add(mspline_log_haz(eta_event01,basis_event01,coefs01, pstream__));
                }
                current_statement_begin__ = 618;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 618;
                    lp_accum__.add(mspline_log_surv(eta_event01,ibasis_event01,coefs01, pstream__));
                }
            } else if (as_bool(logical_eq(type01,5))) {

                current_statement_begin__ = 620;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 620;
                    lp_accum__.add(exponential_log_haz(eta_event01, pstream__));
                }
                current_statement_begin__ = 621;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 621;
                    lp_accum__.add(exponential_log_surv(eta_event01,t_event01, pstream__));
                }
                current_statement_begin__ = 622;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 622;
                    lp_accum__.add(exponential_log_surv(eta_rcens01,t_rcens01, pstream__));
                }
            } else if (as_bool(logical_eq(type01,6))) {
                {
                current_statement_begin__ = 624;
                local_scalar_t__ scale01;
                (void) scale01;  // dummy to suppress unused var warning

                stan::math::initialize(scale01, DUMMY_VAR__);
                stan::math::fill(scale01,DUMMY_VAR__);
                stan::math::assign(scale01,get_base1(coefs01,1,"coefs01",1));


                current_statement_begin__ = 625;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 625;
                    lp_accum__.add(gompertz_log_haz(eta_event01,t_event01,scale01, pstream__));
                }
                current_statement_begin__ = 626;
                if (as_bool(logical_gt(nevent01,0))) {
                    current_statement_begin__ = 626;
                    lp_accum__.add(gompertz_log_surv(eta_event01,t_event01,scale01, pstream__));
                }
                current_statement_begin__ = 627;
                if (as_bool(logical_gt(nrcens01,0))) {
                    current_statement_begin__ = 627;
                    lp_accum__.add(gompertz_log_surv(eta_rcens01,t_rcens01,scale01, pstream__));
                }
                }
            } else {

                current_statement_begin__ = 629;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Bug found: invalid baseline hazard 01 (without quadrature).";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 632;
            if (as_bool(logical_eq(type02,1))) {
                {
                current_statement_begin__ = 633;
                local_scalar_t__ shape02;
                (void) shape02;  // dummy to suppress unused var warning

                stan::math::initialize(shape02, DUMMY_VAR__);
                stan::math::fill(shape02,DUMMY_VAR__);
                stan::math::assign(shape02,get_base1(coefs02,1,"coefs02",1));


                current_statement_begin__ = 634;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 634;
                    lp_accum__.add(weibull_log_haz(eta_event02,t_event02,shape02, pstream__));
                }
                current_statement_begin__ = 635;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 635;
                    lp_accum__.add(weibull_log_surv(eta_event02,t_event02,shape02, pstream__));
                }
                current_statement_begin__ = 636;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 636;
                    lp_accum__.add(weibull_log_surv(eta_rcens02,t_rcens02,shape02, pstream__));
                }
                }
            } else if (as_bool(logical_eq(type02,4))) {

                current_statement_begin__ = 638;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 638;
                    lp_accum__.add(mspline_log_surv(eta_rcens02,ibasis_rcens02,coefs02, pstream__));
                }
                current_statement_begin__ = 639;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 639;
                    lp_accum__.add(mspline_log_haz(eta_event02,basis_event02,coefs02, pstream__));
                }
                current_statement_begin__ = 640;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 640;
                    lp_accum__.add(mspline_log_surv(eta_event02,ibasis_event02,coefs02, pstream__));
                }
            } else if (as_bool(logical_eq(type02,5))) {

                current_statement_begin__ = 642;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 642;
                    lp_accum__.add(exponential_log_haz(eta_event02, pstream__));
                }
                current_statement_begin__ = 643;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 643;
                    lp_accum__.add(exponential_log_surv(eta_event02,t_event02, pstream__));
                }
                current_statement_begin__ = 644;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 644;
                    lp_accum__.add(exponential_log_surv(eta_rcens02,t_rcens02, pstream__));
                }
            } else if (as_bool(logical_eq(type02,6))) {
                {
                current_statement_begin__ = 646;
                local_scalar_t__ scale02;
                (void) scale02;  // dummy to suppress unused var warning

                stan::math::initialize(scale02, DUMMY_VAR__);
                stan::math::fill(scale02,DUMMY_VAR__);
                stan::math::assign(scale02,get_base1(coefs02,1,"coefs02",1));


                current_statement_begin__ = 647;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 647;
                    lp_accum__.add(gompertz_log_haz(eta_event02,t_event02,scale02, pstream__));
                }
                current_statement_begin__ = 648;
                if (as_bool(logical_gt(nevent02,0))) {
                    current_statement_begin__ = 648;
                    lp_accum__.add(gompertz_log_surv(eta_event02,t_event02,scale02, pstream__));
                }
                current_statement_begin__ = 649;
                if (as_bool(logical_gt(nrcens02,0))) {
                    current_statement_begin__ = 649;
                    lp_accum__.add(gompertz_log_surv(eta_rcens02,t_rcens02,scale02, pstream__));
                }
                }
            } else {

                current_statement_begin__ = 651;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Bug found: invalid baseline hazard 02 (without quadrature).";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 654;
            if (as_bool(logical_eq(type12,1))) {
                {
                current_statement_begin__ = 655;
                local_scalar_t__ shape12;
                (void) shape12;  // dummy to suppress unused var warning

                stan::math::initialize(shape12, DUMMY_VAR__);
                stan::math::fill(shape12,DUMMY_VAR__);
                stan::math::assign(shape12,get_base1(coefs12,1,"coefs12",1));


                current_statement_begin__ = 656;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 656;
                    lp_accum__.add(weibull_log_surv(eta_rcens12,t_rcens12,shape12, pstream__));
                }
                current_statement_begin__ = 657;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 657;
                    lp_accum__.add(weibull_log_haz(eta_event12,t_event12,shape12, pstream__));
                }
                current_statement_begin__ = 658;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 658;
                    lp_accum__.add(weibull_log_surv(eta_event12,t_event12,shape12, pstream__));
                }
                }
            } else if (as_bool(logical_eq(type12,4))) {

                current_statement_begin__ = 660;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 660;
                    lp_accum__.add(mspline_log_surv(eta_rcens12,ibasis_rcens12,coefs12, pstream__));
                }
                current_statement_begin__ = 661;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 661;
                    lp_accum__.add(mspline_log_haz(eta_event12,basis_event12,coefs12, pstream__));
                }
                current_statement_begin__ = 662;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 662;
                    lp_accum__.add(mspline_log_surv(eta_event12,ibasis_event12,coefs12, pstream__));
                }
            } else if (as_bool(logical_eq(type12,5))) {

                current_statement_begin__ = 664;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 664;
                    lp_accum__.add(exponential_log_surv(eta_rcens12,t_rcens12, pstream__));
                }
                current_statement_begin__ = 665;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 665;
                    lp_accum__.add(exponential_log_haz(eta_event12, pstream__));
                }
                current_statement_begin__ = 666;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 666;
                    lp_accum__.add(exponential_log_surv(eta_event12,t_event12, pstream__));
                }
            } else if (as_bool(logical_eq(type12,6))) {
                {
                current_statement_begin__ = 668;
                local_scalar_t__ scale12;
                (void) scale12;  // dummy to suppress unused var warning

                stan::math::initialize(scale12, DUMMY_VAR__);
                stan::math::fill(scale12,DUMMY_VAR__);
                stan::math::assign(scale12,get_base1(coefs12,1,"coefs12",1));


                current_statement_begin__ = 669;
                if (as_bool(logical_gt(nrcens12,0))) {
                    current_statement_begin__ = 669;
                    lp_accum__.add(gompertz_log_surv(eta_rcens12,t_rcens12,scale12, pstream__));
                }
                current_statement_begin__ = 670;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 670;
                    lp_accum__.add(gompertz_log_haz(eta_event12,t_event12,scale12, pstream__));
                }
                current_statement_begin__ = 671;
                if (as_bool(logical_gt(nevent12,0))) {
                    current_statement_begin__ = 671;
                    lp_accum__.add(gompertz_log_surv(eta_event12,t_event12,scale12, pstream__));
                }
                }
            } else {

                current_statement_begin__ = 673;
                std::stringstream errmsg_stream__;
                errmsg_stream__ << "Bug found: invalid baseline hazard 12 (without quadrature).";
                throw std::domain_error(errmsg_stream__.str());
            }
            current_statement_begin__ = 680;
            if (as_bool(logical_gt(K01,0))) {
                {
                current_statement_begin__ = 681;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,beta_lp(z_beta01,prior_dist01, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 684;
            if (as_bool(logical_gt(K02,0))) {
                {
                current_statement_begin__ = 685;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,beta_lp(z_beta02,prior_dist02, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 688;
            if (as_bool(logical_gt(K12,0))) {
                {
                current_statement_begin__ = 689;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,beta_lp(z_beta12,prior_dist12, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 693;
            if (as_bool(logical_eq(has_intercept01,1))) {
                {
                current_statement_begin__ = 694;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,gamma_lp(get_base1(gamma01,1,"gamma01",1),prior_dist_for_intercept01,prior_mean_for_intercept01,prior_scale_for_intercept01, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 698;
            if (as_bool(logical_eq(has_intercept02,1))) {
                {
                current_statement_begin__ = 699;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,gamma_lp(get_base1(gamma02,1,"gamma02",1),prior_dist_for_intercept02,prior_mean_for_intercept02,prior_scale_for_intercept02, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 703;
            if (as_bool(logical_eq(has_intercept12,1))) {
                {
                current_statement_begin__ = 704;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,gamma_lp(get_base1(gamma12,1,"gamma12",1),prior_dist_for_intercept12,prior_mean_for_intercept12,prior_scale_for_intercept12, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 708;
            if (as_bool(logical_gt(nvars01,0))) {
                {
                current_statement_begin__ = 709;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,basehaz_lp(z_coefs01,prior_dist_for_aux01, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 712;
            if (as_bool(logical_gt(nvars02,0))) {
                {
                current_statement_begin__ = 713;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,basehaz_lp(z_coefs02,prior_dist_for_aux02, lp__, lp_accum__, pstream__));


                }
            }
            current_statement_begin__ = 716;
            if (as_bool(logical_gt(nvars12,0))) {
                {
                current_statement_begin__ = 717;
                local_scalar_t__ dummy;
                (void) dummy;  // dummy to suppress unused var warning

                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy,DUMMY_VAR__);
                stan::math::assign(dummy,basehaz_lp(z_coefs12,prior_dist_for_aux12, lp__, lp_accum__, pstream__));


                }
            }
            }

        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("z_beta01");
        names__.push_back("z_beta02");
        names__.push_back("z_beta12");
        names__.push_back("z_coefs01");
        names__.push_back("z_coefs02");
        names__.push_back("z_coefs12");
        names__.push_back("gamma01");
        names__.push_back("gamma02");
        names__.push_back("gamma12");
        names__.push_back("beta01");
        names__.push_back("beta02");
        names__.push_back("beta12");
        names__.push_back("coefs01");
        names__.push_back("coefs02");
        names__.push_back("coefs12");
        names__.push_back("alpha01");
        names__.push_back("alpha02");
        names__.push_back("alpha12");
        names__.push_back("aux01");
        names__.push_back("aux02");
        names__.push_back("aux12");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(K01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K12);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars12);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept12);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K12);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars12);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept12);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars01);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars02);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(nvars12);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        typedef double local_scalar_t__;

        vars__.resize(0);
        stan::io::reader<local_scalar_t__> in__(params_r__,params_i__);
        static const char* function__ = "model_MS_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning
        // read-transform, write parameters
        vector_d z_beta01 = in__.vector_constrain(K01);
        vector_d z_beta02 = in__.vector_constrain(K02);
        vector_d z_beta12 = in__.vector_constrain(K12);
        vector_d z_coefs01 = in__.vector_lb_constrain(0,nvars01);
        vector_d z_coefs02 = in__.vector_lb_constrain(0,nvars02);
        vector_d z_coefs12 = in__.vector_lb_constrain(0,nvars12);
        vector<double> gamma01;
        size_t dim_gamma01_0__ = has_intercept01;
        for (size_t k_0__ = 0; k_0__ < dim_gamma01_0__; ++k_0__) {
            gamma01.push_back(in__.scalar_constrain());
        }
        vector<double> gamma02;
        size_t dim_gamma02_0__ = has_intercept02;
        for (size_t k_0__ = 0; k_0__ < dim_gamma02_0__; ++k_0__) {
            gamma02.push_back(in__.scalar_constrain());
        }
        vector<double> gamma12;
        size_t dim_gamma12_0__ = has_intercept12;
        for (size_t k_0__ = 0; k_0__ < dim_gamma12_0__; ++k_0__) {
            gamma12.push_back(in__.scalar_constrain());
        }
            for (int k_0__ = 0; k_0__ < K01; ++k_0__) {
            vars__.push_back(z_beta01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < K02; ++k_0__) {
            vars__.push_back(z_beta02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < K12; ++k_0__) {
            vars__.push_back(z_beta12[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars01; ++k_0__) {
            vars__.push_back(z_coefs01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars02; ++k_0__) {
            vars__.push_back(z_coefs02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars12; ++k_0__) {
            vars__.push_back(z_coefs12[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < has_intercept01; ++k_0__) {
            vars__.push_back(gamma01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < has_intercept02; ++k_0__) {
            vars__.push_back(gamma02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < has_intercept12; ++k_0__) {
            vars__.push_back(gamma12[k_0__]);
            }

        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        try {
            current_statement_begin__ = 515;
            validate_non_negative_index("beta01", "K01", K01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta01(static_cast<Eigen::VectorXd::Index>(K01));
            (void) beta01;  // dummy to suppress unused var warning

            stan::math::initialize(beta01, DUMMY_VAR__);
            stan::math::fill(beta01,DUMMY_VAR__);
            current_statement_begin__ = 516;
            validate_non_negative_index("beta02", "K02", K02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta02(static_cast<Eigen::VectorXd::Index>(K02));
            (void) beta02;  // dummy to suppress unused var warning

            stan::math::initialize(beta02, DUMMY_VAR__);
            stan::math::fill(beta02,DUMMY_VAR__);
            current_statement_begin__ = 517;
            validate_non_negative_index("beta12", "K12", K12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  beta12(static_cast<Eigen::VectorXd::Index>(K12));
            (void) beta12;  // dummy to suppress unused var warning

            stan::math::initialize(beta12, DUMMY_VAR__);
            stan::math::fill(beta12,DUMMY_VAR__);
            current_statement_begin__ = 520;
            validate_non_negative_index("coefs01", "nvars01", nvars01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  coefs01(static_cast<Eigen::VectorXd::Index>(nvars01));
            (void) coefs01;  // dummy to suppress unused var warning

            stan::math::initialize(coefs01, DUMMY_VAR__);
            stan::math::fill(coefs01,DUMMY_VAR__);
            current_statement_begin__ = 521;
            validate_non_negative_index("coefs02", "nvars02", nvars02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  coefs02(static_cast<Eigen::VectorXd::Index>(nvars02));
            (void) coefs02;  // dummy to suppress unused var warning

            stan::math::initialize(coefs02, DUMMY_VAR__);
            stan::math::fill(coefs02,DUMMY_VAR__);
            current_statement_begin__ = 522;
            validate_non_negative_index("coefs12", "nvars12", nvars12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  coefs12(static_cast<Eigen::VectorXd::Index>(nvars12));
            (void) coefs12;  // dummy to suppress unused var warning

            stan::math::initialize(coefs12, DUMMY_VAR__);
            stan::math::fill(coefs12,DUMMY_VAR__);


            current_statement_begin__ = 525;
            if (as_bool(logical_gt(K01,0))) {

                current_statement_begin__ = 526;
                stan::math::assign(beta01, make_beta(z_beta01,prior_dist01,prior_mean01,prior_scale01, pstream__));
            }
            current_statement_begin__ = 529;
            if (as_bool(logical_gt(K02,0))) {

                current_statement_begin__ = 530;
                stan::math::assign(beta02, make_beta(z_beta02,prior_dist02,prior_mean02,prior_scale02, pstream__));
            }
            current_statement_begin__ = 533;
            if (as_bool(logical_gt(K12,0))) {

                current_statement_begin__ = 534;
                stan::math::assign(beta12, make_beta(z_beta12,prior_dist12,prior_mean12,prior_scale12, pstream__));
            }
            current_statement_begin__ = 539;
            if (as_bool(logical_gt(nvars01,0))) {

                current_statement_begin__ = 540;
                stan::math::assign(coefs01, elt_multiply(z_coefs01,prior_scale_for_aux01));
            }
            current_statement_begin__ = 542;
            if (as_bool(logical_gt(nvars02,0))) {

                current_statement_begin__ = 543;
                stan::math::assign(coefs02, elt_multiply(z_coefs02,prior_scale_for_aux02));
            }
            current_statement_begin__ = 545;
            if (as_bool(logical_gt(nvars12,0))) {

                current_statement_begin__ = 546;
                stan::math::assign(coefs12, elt_multiply(z_coefs12,prior_scale_for_aux12));
            }

            // validate transformed parameters
            current_statement_begin__ = 515;
            current_statement_begin__ = 516;
            current_statement_begin__ = 517;
            current_statement_begin__ = 520;
            current_statement_begin__ = 521;
            current_statement_begin__ = 522;

            // write transformed parameters
            if (include_tparams__) {
            for (int k_0__ = 0; k_0__ < K01; ++k_0__) {
            vars__.push_back(beta01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < K02; ++k_0__) {
            vars__.push_back(beta02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < K12; ++k_0__) {
            vars__.push_back(beta12[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars01; ++k_0__) {
            vars__.push_back(coefs01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars02; ++k_0__) {
            vars__.push_back(coefs02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars12; ++k_0__) {
            vars__.push_back(coefs12[k_0__]);
            }
            }
            if (!include_gqs__) return;
            // declare and define generated quantities
            current_statement_begin__ = 727;
            validate_non_negative_index("alpha01", "has_intercept01", has_intercept01);
            vector<local_scalar_t__> alpha01(has_intercept01);
            stan::math::initialize(alpha01, DUMMY_VAR__);
            stan::math::fill(alpha01,DUMMY_VAR__);
            current_statement_begin__ = 728;
            validate_non_negative_index("alpha02", "has_intercept02", has_intercept02);
            vector<local_scalar_t__> alpha02(has_intercept02);
            stan::math::initialize(alpha02, DUMMY_VAR__);
            stan::math::fill(alpha02,DUMMY_VAR__);
            current_statement_begin__ = 729;
            validate_non_negative_index("alpha12", "has_intercept12", has_intercept12);
            vector<local_scalar_t__> alpha12(has_intercept12);
            stan::math::initialize(alpha12, DUMMY_VAR__);
            stan::math::fill(alpha12,DUMMY_VAR__);
            current_statement_begin__ = 731;
            validate_non_negative_index("aux01", "nvars01", nvars01);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  aux01(static_cast<Eigen::VectorXd::Index>(nvars01));
            (void) aux01;  // dummy to suppress unused var warning

            stan::math::initialize(aux01, DUMMY_VAR__);
            stan::math::fill(aux01,DUMMY_VAR__);
            current_statement_begin__ = 732;
            validate_non_negative_index("aux02", "nvars02", nvars02);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  aux02(static_cast<Eigen::VectorXd::Index>(nvars02));
            (void) aux02;  // dummy to suppress unused var warning

            stan::math::initialize(aux02, DUMMY_VAR__);
            stan::math::fill(aux02,DUMMY_VAR__);
            current_statement_begin__ = 733;
            validate_non_negative_index("aux12", "nvars12", nvars12);
            Eigen::Matrix<local_scalar_t__,Eigen::Dynamic,1>  aux12(static_cast<Eigen::VectorXd::Index>(nvars12));
            (void) aux12;  // dummy to suppress unused var warning

            stan::math::initialize(aux12, DUMMY_VAR__);
            stan::math::fill(aux12,DUMMY_VAR__);


            current_statement_begin__ = 736;
            if (as_bool(logical_eq(type01,4))) {

                current_statement_begin__ = 737;
                stan::math::assign(aux01, multiply(coefs01,stan::math::exp((log_crude_event_rate01 - dot_product(x_bar01,beta01)))));
            } else {

                current_statement_begin__ = 739;
                stan::math::assign(aux01, coefs01);
                current_statement_begin__ = 740;
                stan::model::assign(alpha01, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            ((log_crude_event_rate01 - dot_product(x_bar01,beta01)) + get_base1(gamma01,1,"gamma01",1)), 
                            "assigning variable alpha01");
            }
            current_statement_begin__ = 742;
            if (as_bool(logical_eq(type02,4))) {

                current_statement_begin__ = 743;
                stan::math::assign(aux02, multiply(coefs02,stan::math::exp((log_crude_event_rate02 - dot_product(x_bar02,beta02)))));
            } else {

                current_statement_begin__ = 745;
                stan::math::assign(aux02, coefs02);
                current_statement_begin__ = 746;
                stan::model::assign(alpha02, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            ((log_crude_event_rate02 - dot_product(x_bar02,beta02)) + get_base1(gamma02,1,"gamma02",1)), 
                            "assigning variable alpha02");
            }
            current_statement_begin__ = 748;
            if (as_bool(logical_eq(type12,4))) {

                current_statement_begin__ = 749;
                stan::math::assign(aux12, multiply(coefs12,stan::math::exp((log_crude_event_rate12 - dot_product(x_bar12,beta12)))));
            } else {

                current_statement_begin__ = 751;
                stan::math::assign(aux12, coefs12);
                current_statement_begin__ = 752;
                stan::model::assign(alpha12, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            ((log_crude_event_rate12 - dot_product(x_bar12,beta12)) + get_base1(gamma12,1,"gamma12",1)), 
                            "assigning variable alpha12");
            }

            // validate generated quantities
            current_statement_begin__ = 727;
            current_statement_begin__ = 728;
            current_statement_begin__ = 729;
            current_statement_begin__ = 731;
            current_statement_begin__ = 732;
            current_statement_begin__ = 733;

            // write generated quantities
            for (int k_0__ = 0; k_0__ < has_intercept01; ++k_0__) {
            vars__.push_back(alpha01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < has_intercept02; ++k_0__) {
            vars__.push_back(alpha02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < has_intercept12; ++k_0__) {
            vars__.push_back(alpha12[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars01; ++k_0__) {
            vars__.push_back(aux01[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars02; ++k_0__) {
            vars__.push_back(aux02[k_0__]);
            }
            for (int k_0__ = 0; k_0__ < nvars12; ++k_0__) {
            vars__.push_back(aux12[k_0__]);
            }

        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_MS";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= K01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_coefs01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_coefs02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_coefs12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;

        if (include_tparams__) {
            for (int k_0__ = 1; k_0__ <= K01; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta01" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= K02; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta02" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= K12; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta12" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= nvars01; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "coefs01" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= nvars02; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "coefs02" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= nvars12; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "coefs12" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
        }


        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        for (int k_0__ = 1; k_0__ <= K01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= K12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_coefs01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_coefs02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_coefs12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;

        if (include_tparams__) {
            for (int k_0__ = 1; k_0__ <= K01; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta01" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= K02; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta02" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= K12; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta12" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= nvars01; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "coefs01" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= nvars02; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "coefs02" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
            for (int k_0__ = 1; k_0__ <= nvars12; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "coefs12" << '.' << k_0__;
                param_names__.push_back(param_name_stream__.str());
            }
        }


        if (!include_gqs__) return;
        for (int k_0__ = 1; k_0__ <= has_intercept01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= has_intercept12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars01; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux01" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars02; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux02" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
        for (int k_0__ = 1; k_0__ <= nvars12; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux12" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }
    }

}; // model

}

typedef model_MS_namespace::model_MS stan_model;


#endif
